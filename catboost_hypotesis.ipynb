{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/projects/ppashin/.local/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/tmp/ipykernel_173229/2248810513.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt    \n",
    "from fastparquet import ParquetFile\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "from utils import remove_highly_correlated_features, feature_drop\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Data/train_ai_comp_final_dp.parquet\"\n",
    "pf = ParquetFile(file_path)\n",
    "df = pf.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fature_to_drop = remove_highly_correlated_features(df, threshold=0.94)\n",
    "df.drop(columns=fature_to_drop, inplace=True)\n",
    "df = feature_drop(df)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:29:26,666] A new study created in memory with name: no-name-4f12ccd2-964b-4d7e-b14b-3f8da52dbf00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6901089\ttest: 0.6901159\tbest: 0.6901159 (0)\ttotal: 80.9ms\tremaining: 30.6s\n",
      "100:\tlearn: 0.4589726\ttest: 0.4594493\tbest: 0.4594493 (100)\ttotal: 6.34s\tremaining: 17.5s\n",
      "200:\tlearn: 0.3284557\ttest: 0.3293326\tbest: 0.3293326 (200)\ttotal: 12.5s\tremaining: 11.1s\n",
      "300:\tlearn: 0.2540422\ttest: 0.2552969\tbest: 0.2552969 (300)\ttotal: 18.7s\tremaining: 4.84s\n",
      "378:\tlearn: 0.2182098\ttest: 0.2197252\tbest: 0.2197252 (378)\ttotal: 23.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2197252273\n",
      "bestIteration = 378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:29:51,337] Trial 0 finished with value: 0.9641080415307487 and parameters: {'iterations': 379, 'learning_rate': 0.0018214514701896244, 'depth': 8, 'l2_leaf_reg': 0.13923648506539132, 'border_count': 107, 'bagging_temperature': 6.388009669759876, 'random_strength': 6.065009944146732e-07}. Best is trial 0 with value: 0.9641080415307487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5540710\ttest: 0.5544735\tbest: 0.5544735 (0)\ttotal: 89.8ms\tremaining: 1m 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:29:57,114] Trial 1 finished with value: 0.9640406839679379 and parameters: {'iterations': 771, 'learning_rate': 0.0907337864350032, 'depth': 9, 'l2_leaf_reg': 2.9955721382375857e-06, 'border_count': 19, 'bagging_temperature': 3.515027877040358, 'random_strength': 0.004076859439917506}. Best is trial 0 with value: 0.9641080415307487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1452641565\n",
      "bestIteration = 21\n",
      "\n",
      "Shrink model to first 22 iterations.\n",
      "0:\tlearn: 0.6873074\ttest: 0.6873260\tbest: 0.6873260 (0)\ttotal: 232ms\tremaining: 1m 31s\n",
      "100:\tlearn: 0.3349630\ttest: 0.3358271\tbest: 0.3358271 (100)\ttotal: 20.7s\tremaining: 1m\n",
      "200:\tlearn: 0.2145154\ttest: 0.2163504\tbest: 0.2163504 (200)\ttotal: 41.4s\tremaining: 40s\n",
      "300:\tlearn: 0.1697562\ttest: 0.1725962\tbest: 0.1725962 (300)\ttotal: 1m 2s\tremaining: 19.4s\n",
      "394:\tlearn: 0.1519065\ttest: 0.1557666\tbest: 0.1557666 (394)\ttotal: 1m 21s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1557666168\n",
      "bestIteration = 394\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:31:20,149] Trial 2 finished with value: 0.9640984190217757 and parameters: {'iterations': 395, 'learning_rate': 0.0035831057248123578, 'depth': 10, 'l2_leaf_reg': 0.076498894834829, 'border_count': 232, 'bagging_temperature': 7.108296475382758, 'random_strength': 0.14380376944283146}. Best is trial 0 with value: 0.9641080415307487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6898225\ttest: 0.6898392\tbest: 0.6898392 (0)\ttotal: 69.9ms\tremaining: 1m 5s\n",
      "100:\tlearn: 0.4431325\ttest: 0.4435830\tbest: 0.4435830 (100)\ttotal: 7.27s\tremaining: 1m\n",
      "200:\tlearn: 0.3112511\ttest: 0.3120807\tbest: 0.3120807 (200)\ttotal: 14.4s\tremaining: 52.8s\n",
      "300:\tlearn: 0.2395895\ttest: 0.2407818\tbest: 0.2407818 (300)\ttotal: 21.5s\tremaining: 45.5s\n",
      "400:\tlearn: 0.1994598\ttest: 0.2009661\tbest: 0.2009661 (400)\ttotal: 28.7s\tremaining: 38.4s\n",
      "500:\tlearn: 0.1763489\ttest: 0.1781209\tbest: 0.1781209 (500)\ttotal: 35.9s\tremaining: 31.3s\n",
      "600:\tlearn: 0.1625342\ttest: 0.1645480\tbest: 0.1645480 (600)\ttotal: 43.3s\tremaining: 24.2s\n",
      "700:\tlearn: 0.1540853\ttest: 0.1563250\tbest: 0.1563250 (700)\ttotal: 50.7s\tremaining: 17.1s\n",
      "800:\tlearn: 0.1487635\ttest: 0.1512193\tbest: 0.1512193 (800)\ttotal: 58.3s\tremaining: 9.89s\n",
      "900:\tlearn: 0.1453181\ttest: 0.1479684\tbest: 0.1479684 (900)\ttotal: 1m 5s\tremaining: 2.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:32:29,757] Trial 3 finished with value: 0.9640984190217757 and parameters: {'iterations': 937, 'learning_rate': 0.0020024066381994477, 'depth': 7, 'l2_leaf_reg': 0.015859389032544465, 'border_count': 163, 'bagging_temperature': 42.71968524796292, 'random_strength': 0.001565059724409236}. Best is trial 0 with value: 0.9641080415307487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936:\tlearn: 0.1443936\ttest: 0.1471144\tbest: 0.1471144 (936)\ttotal: 1m 8s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1471144364\n",
      "bestIteration = 936\n",
      "\n",
      "0:\tlearn: 0.6843353\ttest: 0.6843572\tbest: 0.6843572 (0)\ttotal: 69.7ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.2569721\ttest: 0.2581369\tbest: 0.2581369 (100)\ttotal: 5.79s\tremaining: 7.34s\n",
      "200:\tlearn: 0.1700091\ttest: 0.1719763\tbest: 0.1719763 (200)\ttotal: 11.9s\tremaining: 1.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:32:44,263] Trial 4 finished with value: 0.9640791740038298 and parameters: {'iterations': 229, 'learning_rate': 0.005360310662197945, 'depth': 7, 'l2_leaf_reg': 2.7773734847722597e-08, 'border_count': 234, 'bagging_temperature': 4.126566968676439, 'random_strength': 0.0008487848645879283}. Best is trial 0 with value: 0.9641080415307487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228:\tlearn: 0.1609451\ttest: 0.1630872\tbest: 0.1630872 (228)\ttotal: 13.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1630872456\n",
      "bestIteration = 228\n",
      "\n",
      "0:\tlearn: 0.6164309\ttest: 0.6166670\tbest: 0.6166670 (0)\ttotal: 105ms\tremaining: 11.6s\n",
      "100:\tlearn: 0.1319618\ttest: 0.1404441\tbest: 0.1404441 (100)\ttotal: 9.01s\tremaining: 892ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:32:55,296] Trial 5 finished with value: 0.9641753990935596 and parameters: {'iterations': 111, 'learning_rate': 0.04826417429001852, 'depth': 9, 'l2_leaf_reg': 0.08398314732164144, 'border_count': 98, 'bagging_temperature': 55.89212412368227, 'random_strength': 0.05471602596321361}. Best is trial 5 with value: 0.9641753990935596.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110:\tlearn: 0.1313431\ttest: 0.1403357\tbest: 0.1403357 (110)\ttotal: 9.96s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1403356677\n",
      "bestIteration = 110\n",
      "\n",
      "0:\tlearn: 0.6502169\ttest: 0.6503526\tbest: 0.6503526 (0)\ttotal: 133ms\tremaining: 2m 8s\n",
      "100:\tlearn: 0.1386792\ttest: 0.1421137\tbest: 0.1421137 (100)\ttotal: 10.9s\tremaining: 1m 33s\n",
      "200:\tlearn: 0.1349914\ttest: 0.1402683\tbest: 0.1402683 (200)\ttotal: 22.7s\tremaining: 1m 26s\n",
      "300:\tlearn: 0.1340230\ttest: 0.1400058\tbest: 0.1400058 (300)\ttotal: 32.9s\tremaining: 1m 12s\n",
      "400:\tlearn: 0.1324027\ttest: 0.1396788\tbest: 0.1396778 (399)\ttotal: 43.2s\tremaining: 1m 1s\n",
      "500:\tlearn: 0.1311118\ttest: 0.1394748\tbest: 0.1394748 (500)\ttotal: 53.4s\tremaining: 49.6s\n",
      "600:\tlearn: 0.1306527\ttest: 0.1394618\tbest: 0.1394603 (557)\ttotal: 1m 2s\tremaining: 38.1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1394603195\n",
      "bestIteration = 557\n",
      "\n",
      "Shrink model to first 558 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:33:59,584] Trial 6 finished with value: 0.9641850216025326 and parameters: {'iterations': 967, 'learning_rate': 0.02658897321419524, 'depth': 9, 'l2_leaf_reg': 69.82128787993716, 'border_count': 173, 'bagging_temperature': 6.442235736265833, 'random_strength': 0.04395871461511254}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6899998\ttest: 0.6900132\tbest: 0.6900132 (0)\ttotal: 217ms\tremaining: 3m 21s\n",
      "100:\tlearn: 0.4523545\ttest: 0.4529686\tbest: 0.4529686 (100)\ttotal: 20.5s\tremaining: 2m 47s\n",
      "200:\tlearn: 0.3213814\ttest: 0.3224855\tbest: 0.3224855 (200)\ttotal: 40.7s\tremaining: 2m 27s\n",
      "300:\tlearn: 0.2475363\ttest: 0.2491239\tbest: 0.2491239 (300)\ttotal: 1m\tremaining: 2m 5s\n",
      "400:\tlearn: 0.2050552\ttest: 0.2071000\tbest: 0.2071000 (400)\ttotal: 1m 19s\tremaining: 1m 44s\n",
      "500:\tlearn: 0.1800323\ttest: 0.1824910\tbest: 0.1824910 (500)\ttotal: 1m 39s\tremaining: 1m 24s\n",
      "600:\tlearn: 0.1646640\ttest: 0.1675301\tbest: 0.1675301 (600)\ttotal: 1m 58s\tremaining: 1m 4s\n",
      "700:\tlearn: 0.1549935\ttest: 0.1582545\tbest: 0.1582545 (700)\ttotal: 2m 18s\tremaining: 44.9s\n",
      "800:\tlearn: 0.1487269\ttest: 0.1523606\tbest: 0.1523606 (800)\ttotal: 2m 37s\tremaining: 25.2s\n",
      "900:\tlearn: 0.1445653\ttest: 0.1485610\tbest: 0.1485610 (900)\ttotal: 2m 57s\tremaining: 5.5s\n",
      "928:\tlearn: 0.1436537\ttest: 0.1477496\tbest: 0.1477496 (928)\ttotal: 3m 2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1477495852\n",
      "bestIteration = 928\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:37:03,176] Trial 7 finished with value: 0.9641176640397218 and parameters: {'iterations': 929, 'learning_rate': 0.0018789283893821023, 'depth': 10, 'l2_leaf_reg': 5.277859430285405, 'border_count': 170, 'bagging_temperature': 1.341974740167281, 'random_strength': 0.023284862185227195}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6883409\ttest: 0.6883493\tbest: 0.6883493 (0)\ttotal: 49.7ms\tremaining: 8.15s\n",
      "100:\tlearn: 0.3713537\ttest: 0.3718453\tbest: 0.3718453 (100)\ttotal: 3.76s\tremaining: 2.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:37:10,072] Trial 8 finished with value: 0.9640984190217757 and parameters: {'iterations': 165, 'learning_rate': 0.0029606729656976344, 'depth': 5, 'l2_leaf_reg': 0.1868449634798751, 'border_count': 95, 'bagging_temperature': 3.5279259838056953, 'random_strength': 0.00926659943107888}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164:\tlearn: 0.2774901\ttest: 0.2782638\tbest: 0.2782638 (164)\ttotal: 6.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2782637948\n",
      "bestIteration = 164\n",
      "\n",
      "0:\tlearn: 0.5877857\ttest: 0.5880079\tbest: 0.5880079 (0)\ttotal: 175ms\tremaining: 2m 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:37:24,399] Trial 9 finished with value: 0.9641080415307487 and parameters: {'iterations': 815, 'learning_rate': 0.06888180724705877, 'depth': 10, 'l2_leaf_reg': 0.00010930994189362305, 'border_count': 42, 'bagging_temperature': 65.68430176588623, 'random_strength': 0.17327256057937157}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1427787064\n",
      "bestIteration = 37\n",
      "\n",
      "Shrink model to first 38 iterations.\n",
      "0:\tlearn: 0.6653243\ttest: 0.6653969\tbest: 0.6653969 (0)\ttotal: 49.2ms\tremaining: 30.9s\n",
      "100:\tlearn: 0.1481570\ttest: 0.1500759\tbest: 0.1500759 (100)\ttotal: 3.42s\tremaining: 17.9s\n",
      "200:\tlearn: 0.1400032\ttest: 0.1426463\tbest: 0.1426463 (200)\ttotal: 6.9s\tremaining: 14.7s\n",
      "300:\tlearn: 0.1387216\ttest: 0.1417320\tbest: 0.1417320 (300)\ttotal: 10.4s\tremaining: 11.3s\n",
      "400:\tlearn: 0.1380391\ttest: 0.1412759\tbest: 0.1412759 (400)\ttotal: 13.9s\tremaining: 7.89s\n",
      "500:\tlearn: 0.1375551\ttest: 0.1409804\tbest: 0.1409804 (500)\ttotal: 17.5s\tremaining: 4.46s\n",
      "600:\tlearn: 0.1372384\ttest: 0.1408050\tbest: 0.1408050 (600)\ttotal: 20.8s\tremaining: 968ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:37:47,072] Trial 10 finished with value: 0.9640887965128028 and parameters: {'iterations': 629, 'learning_rate': 0.017394460499227316, 'depth': 4, 'l2_leaf_reg': 26.202596280754044, 'border_count': 181, 'bagging_temperature': 18.422950281790417, 'random_strength': 1.0125359144673647e-05}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628:\tlearn: 0.1371499\ttest: 0.1407587\tbest: 0.1407587 (628)\ttotal: 21.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1407586857\n",
      "bestIteration = 628\n",
      "\n",
      "0:\tlearn: 0.6538794\ttest: 0.6539581\tbest: 0.6539581 (0)\ttotal: 77.6ms\tremaining: 37.8s\n",
      "100:\tlearn: 0.1409111\ttest: 0.1436078\tbest: 0.1436078 (100)\ttotal: 8.62s\tremaining: 33s\n",
      "200:\tlearn: 0.1365552\ttest: 0.1409055\tbest: 0.1409055 (200)\ttotal: 17.3s\tremaining: 24.7s\n",
      "300:\tlearn: 0.1347193\ttest: 0.1402647\tbest: 0.1402647 (300)\ttotal: 26s\tremaining: 16.2s\n",
      "400:\tlearn: 0.1333699\ttest: 0.1399223\tbest: 0.1399223 (400)\ttotal: 34.5s\tremaining: 7.48s\n",
      "487:\tlearn: 0.1324551\ttest: 0.1397677\tbest: 0.1397676 (486)\ttotal: 41.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1397676434\n",
      "bestIteration = 486\n",
      "\n",
      "Shrink model to first 487 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:38:29,950] Trial 11 finished with value: 0.9641850216025326 and parameters: {'iterations': 488, 'learning_rate': 0.02604600844351376, 'depth': 8, 'l2_leaf_reg': 27.10416864989904, 'border_count': 71, 'bagging_temperature': 19.836877254791684, 'random_strength': 0.9543806349350501}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6624999\ttest: 0.6625842\tbest: 0.6625842 (0)\ttotal: 76.1ms\tremaining: 40.7s\n",
      "100:\tlearn: 0.1447682\ttest: 0.1469256\tbest: 0.1469256 (100)\ttotal: 8.51s\tremaining: 36.6s\n",
      "200:\tlearn: 0.1378701\ttest: 0.1414254\tbest: 0.1414254 (200)\ttotal: 17.2s\tremaining: 28.6s\n",
      "300:\tlearn: 0.1361020\ttest: 0.1406030\tbest: 0.1406030 (300)\ttotal: 25.9s\tremaining: 20.2s\n",
      "400:\tlearn: 0.1349114\ttest: 0.1401735\tbest: 0.1401735 (400)\ttotal: 34.5s\tremaining: 11.5s\n",
      "500:\tlearn: 0.1339021\ttest: 0.1399007\tbest: 0.1399007 (500)\ttotal: 43s\tremaining: 2.92s\n",
      "534:\tlearn: 0.1335875\ttest: 0.1398095\tbest: 0.1398095 (534)\ttotal: 45.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1398094569\n",
      "bestIteration = 534\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:39:16,794] Trial 12 finished with value: 0.9641465315666407 and parameters: {'iterations': 535, 'learning_rate': 0.02024433407608719, 'depth': 8, 'l2_leaf_reg': 57.900138763498944, 'border_count': 71, 'bagging_temperature': 17.80206081478529, 'random_strength': 0.8216478400112532}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6509446\ttest: 0.6510665\tbest: 0.6510665 (0)\ttotal: 58.6ms\tremaining: 34.6s\n",
      "100:\tlearn: 0.1403687\ttest: 0.1430229\tbest: 0.1430229 (100)\ttotal: 4.86s\tremaining: 23.6s\n",
      "200:\tlearn: 0.1372101\ttest: 0.1408298\tbest: 0.1408298 (200)\ttotal: 9.67s\tremaining: 18.8s\n",
      "300:\tlearn: 0.1359765\ttest: 0.1402798\tbest: 0.1402798 (300)\ttotal: 14.4s\tremaining: 13.9s\n",
      "400:\tlearn: 0.1350516\ttest: 0.1399807\tbest: 0.1399805 (399)\ttotal: 19.1s\tremaining: 9.07s\n",
      "500:\tlearn: 0.1343067\ttest: 0.1397711\tbest: 0.1397711 (500)\ttotal: 23.6s\tremaining: 4.24s\n",
      "590:\tlearn: 0.1337794\ttest: 0.1396887\tbest: 0.1396879 (584)\ttotal: 27.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1396878648\n",
      "bestIteration = 584\n",
      "\n",
      "Shrink model to first 585 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:39:45,180] Trial 13 finished with value: 0.9641272865486947 and parameters: {'iterations': 591, 'learning_rate': 0.0261720462957187, 'depth': 6, 'l2_leaf_reg': 4.237867819218878, 'border_count': 140, 'bagging_temperature': 18.921126756050928, 'random_strength': 5.788866454696822e-05}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6775860\ttest: 0.6776403\tbest: 0.6776403 (0)\ttotal: 94.3ms\tremaining: 41.3s\n",
      "100:\tlearn: 0.1803669\ttest: 0.1825293\tbest: 0.1825293 (100)\ttotal: 7.57s\tremaining: 25.3s\n",
      "200:\tlearn: 0.1438489\ttest: 0.1468288\tbest: 0.1468288 (200)\ttotal: 15.1s\tremaining: 17.9s\n",
      "300:\tlearn: 0.1387645\ttest: 0.1431852\tbest: 0.1431852 (300)\ttotal: 22.9s\tremaining: 10.5s\n",
      "400:\tlearn: 0.1368870\ttest: 0.1421402\tbest: 0.1421402 (400)\ttotal: 30.3s\tremaining: 2.87s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:40:19,193] Trial 14 finished with value: 0.9641369090576677 and parameters: {'iterations': 439, 'learning_rate': 0.009338487232988092, 'depth': 8, 'l2_leaf_reg': 0.00125534984885279, 'border_count': 201, 'bagging_temperature': 1.4472513013016313, 'random_strength': 4.9752454371711714e-08}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438:\tlearn: 0.1363059\ttest: 0.1419594\tbest: 0.1419594 (438)\ttotal: 33.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1419593796\n",
      "bestIteration = 438\n",
      "\n",
      "0:\tlearn: 0.6353823\ttest: 0.6355263\tbest: 0.6355263 (0)\ttotal: 89.4ms\tremaining: 1m 5s\n",
      "100:\tlearn: 0.1359161\ttest: 0.1413828\tbest: 0.1413828 (100)\ttotal: 8.25s\tremaining: 51.6s\n",
      "200:\tlearn: 0.1310888\ttest: 0.1402165\tbest: 0.1402165 (200)\ttotal: 16.5s\tremaining: 43.6s\n",
      "300:\tlearn: 0.1280165\ttest: 0.1398502\tbest: 0.1398502 (300)\ttotal: 24.5s\tremaining: 35.1s\n",
      "400:\tlearn: 0.1256624\ttest: 0.1395746\tbest: 0.1395746 (400)\ttotal: 32.1s\tremaining: 26.6s\n",
      "500:\tlearn: 0.1235217\ttest: 0.1395579\tbest: 0.1395017 (450)\ttotal: 39.7s\tremaining: 18.4s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1395016907\n",
      "bestIteration = 450\n",
      "\n",
      "Shrink model to first 451 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:40:59,927] Trial 15 finished with value: 0.9641369090576677 and parameters: {'iterations': 733, 'learning_rate': 0.038135356050125746, 'depth': 9, 'l2_leaf_reg': 1.5574897780323855, 'border_count': 63, 'bagging_temperature': 27.993485332250682, 'random_strength': 0.7557112326889771}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6756135\ttest: 0.6756734\tbest: 0.6756734 (0)\ttotal: 63.1ms\tremaining: 19.4s\n",
      "100:\tlearn: 0.1714021\ttest: 0.1728897\tbest: 0.1728897 (100)\ttotal: 4.66s\tremaining: 9.55s\n",
      "200:\tlearn: 0.1430181\ttest: 0.1453223\tbest: 0.1453223 (200)\ttotal: 9.37s\tremaining: 4.99s\n",
      "300:\tlearn: 0.1392702\ttest: 0.1421013\tbest: 0.1421013 (300)\ttotal: 14.2s\tremaining: 330ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:41:15,355] Trial 16 finished with value: 0.9640791740038298 and parameters: {'iterations': 308, 'learning_rate': 0.010639728965247551, 'depth': 6, 'l2_leaf_reg': 82.25015117356021, 'border_count': 137, 'bagging_temperature': 10.940021844888722, 'random_strength': 0.00014292338868302366}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307:\tlearn: 0.1391566\ttest: 0.1420178\tbest: 0.1420178 (307)\ttotal: 14.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1420177963\n",
      "bestIteration = 307\n",
      "\n",
      "0:\tlearn: 0.6757679\ttest: 0.6758100\tbest: 0.6758100 (0)\ttotal: 82.8ms\tremaining: 40.1s\n",
      "100:\tlearn: 0.1703369\ttest: 0.1719740\tbest: 0.1719740 (100)\ttotal: 5.74s\tremaining: 21.8s\n",
      "200:\tlearn: 0.1424574\ttest: 0.1452271\tbest: 0.1452271 (200)\ttotal: 11.5s\tremaining: 16.2s\n",
      "300:\tlearn: 0.1381571\ttest: 0.1421693\tbest: 0.1421693 (300)\ttotal: 17.4s\tremaining: 10.7s\n",
      "400:\tlearn: 0.1362753\ttest: 0.1413428\tbest: 0.1413428 (400)\ttotal: 23.2s\tremaining: 4.87s\n",
      "484:\tlearn: 0.1351256\ttest: 0.1409823\tbest: 0.1409823 (484)\ttotal: 28.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.140982342\n",
      "bestIteration = 484\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:41:44,390] Trial 17 finished with value: 0.9640984190217757 and parameters: {'iterations': 485, 'learning_rate': 0.011320119277877723, 'depth': 8, 'l2_leaf_reg': 0.0023694907076421703, 'border_count': 8, 'bagging_temperature': 10.908807521927466, 'random_strength': 0.7549839007890735}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6301151\ttest: 0.6303463\tbest: 0.6303463 (0)\ttotal: 130ms\tremaining: 1m 27s\n",
      "100:\tlearn: 0.1337407\ttest: 0.1412205\tbest: 0.1412205 (100)\ttotal: 11s\tremaining: 1m 2s\n",
      "200:\tlearn: 0.1280735\ttest: 0.1404198\tbest: 0.1404198 (200)\ttotal: 21.3s\tremaining: 50.3s\n",
      "300:\tlearn: 0.1236387\ttest: 0.1487911\tbest: 0.1402385 (282)\ttotal: 31.5s\tremaining: 39.2s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1402384906\n",
      "bestIteration = 282\n",
      "\n",
      "Shrink model to first 283 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:42:20,098] Trial 18 finished with value: 0.9641850216025326 and parameters: {'iterations': 675, 'learning_rate': 0.03897146595264372, 'depth': 9, 'l2_leaf_reg': 4.388842739409182e-05, 'border_count': 215, 'bagging_temperature': 37.60823804412858, 'random_strength': 0.024314872567937438}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6669845\ttest: 0.6670613\tbest: 0.6670613 (0)\ttotal: 60.5ms\tremaining: 53.6s\n",
      "100:\tlearn: 0.1487554\ttest: 0.1508869\tbest: 0.1508869 (100)\ttotal: 4.72s\tremaining: 36.8s\n",
      "200:\tlearn: 0.1388232\ttest: 0.1420179\tbest: 0.1420179 (200)\ttotal: 9.46s\tremaining: 32.4s\n",
      "300:\tlearn: 0.1370878\ttest: 0.1410822\tbest: 0.1410822 (300)\ttotal: 14.1s\tremaining: 27.6s\n",
      "400:\tlearn: 0.1359528\ttest: 0.1406965\tbest: 0.1406965 (400)\ttotal: 18.7s\tremaining: 22.7s\n",
      "500:\tlearn: 0.1350312\ttest: 0.1404731\tbest: 0.1404731 (500)\ttotal: 23.2s\tremaining: 17.9s\n",
      "600:\tlearn: 0.1342063\ttest: 0.1402834\tbest: 0.1402834 (600)\ttotal: 27.6s\tremaining: 13.2s\n",
      "700:\tlearn: 0.1334358\ttest: 0.1401674\tbest: 0.1401674 (700)\ttotal: 31.8s\tremaining: 8.49s\n",
      "800:\tlearn: 0.1327382\ttest: 0.1400564\tbest: 0.1400564 (800)\ttotal: 36.3s\tremaining: 3.94s\n",
      "887:\tlearn: 0.1321880\ttest: 0.1399882\tbest: 0.1399882 (887)\ttotal: 39.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1399881759\n",
      "bestIteration = 887\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:43:00,935] Trial 19 finished with value: 0.9641465315666407 and parameters: {'iterations': 888, 'learning_rate': 0.01613041049950429, 'depth': 6, 'l2_leaf_reg': 1.0289368990261868e-08, 'border_count': 123, 'bagging_temperature': 2.145380597579815, 'random_strength': 0.00036256205069602537}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6824691\ttest: 0.6825130\tbest: 0.6825130 (0)\ttotal: 66.1ms\tremaining: 19.8s\n",
      "100:\tlearn: 0.2278266\ttest: 0.2289900\tbest: 0.2289900 (100)\ttotal: 6.02s\tremaining: 11.9s\n",
      "200:\tlearn: 0.1581400\ttest: 0.1600654\tbest: 0.1600654 (200)\ttotal: 12.3s\tremaining: 6.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:43:20,467] Trial 20 finished with value: 0.9640984190217757 and parameters: {'iterations': 300, 'learning_rate': 0.0064297953404262465, 'depth': 7, 'l2_leaf_reg': 5.377716817754953, 'border_count': 67, 'bagging_temperature': 99.46574830126507, 'random_strength': 4.259009323313773e-06}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299:\tlearn: 0.1438662\ttest: 0.1463626\tbest: 0.1463626 (299)\ttotal: 18.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1463626078\n",
      "bestIteration = 299\n",
      "\n",
      "0:\tlearn: 0.6344628\ttest: 0.6346573\tbest: 0.6346573 (0)\ttotal: 131ms\tremaining: 1m 27s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1585924301\n",
      "bestIteration = 35\n",
      "\n",
      "Shrink model to first 36 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:43:30,804] Trial 21 finished with value: 0.9640599289858838 and parameters: {'iterations': 674, 'learning_rate': 0.03621156640968378, 'depth': 9, 'l2_leaf_reg': 0.00011809723250671714, 'border_count': 211, 'bagging_temperature': 30.15235342695951, 'random_strength': 0.03784267704983452}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6439145\ttest: 0.6440336\tbest: 0.6440336 (0)\ttotal: 124ms\tremaining: 2m 3s\n",
      "100:\tlearn: 0.1372416\ttest: 0.8546970\tbest: 0.1456733 (63)\ttotal: 10.7s\tremaining: 1m 34s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.145673307\n",
      "bestIteration = 63\n",
      "\n",
      "Shrink model to first 64 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 17:43:43,779] Trial 22 finished with value: 0.9640791740038298 and parameters: {'iterations': 995, 'learning_rate': 0.03125742185973268, 'depth': 9, 'l2_leaf_reg': 3.80014646505508e-06, 'border_count': 201, 'bagging_temperature': 29.728127692927778, 'random_strength': 0.1311106348339184}. Best is trial 6 with value: 0.9641850216025326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5985717\ttest: 0.5988757\tbest: 0.5988757 (0)\ttotal: 92.8ms\tremaining: 1m 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-03-11 17:43:49,673] Trial 23 failed with parameters: {'iterations': 690, 'learning_rate': 0.06005759286395733, 'depth': 8, 'l2_leaf_reg': 6.839404574591889e-06, 'border_count': 244, 'bagging_temperature': 14.32040651248944, 'random_strength': 0.003056473630504032} because of the following error: CatBoostError('/src/catboost/catboost/private/libs/algo/tensor_search_helpers.cpp:99: This should be unreachable').\n",
      "Traceback (most recent call last):\n",
      "  File \"/cephfs/projects/ppashin/.local/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_152839/816748112.py\", line 20, in objective\n",
      "    model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=50, verbose=100)\n",
      "  File \"/cephfs/projects/ppashin/.local/lib/python3.11/site-packages/catboost/core.py\", line 5201, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/cephfs/projects/ppashin/.local/lib/python3.11/site-packages/catboost/core.py\", line 2396, in _fit\n",
      "    self._train(\n",
      "  File \"/cephfs/projects/ppashin/.local/lib/python3.11/site-packages/catboost/core.py\", line 1776, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4833, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4882, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: /src/catboost/catboost/private/libs/algo/tensor_search_helpers.cpp:99: This should be unreachable\n",
      "[W 2024-03-11 17:43:49,684] Trial 23 failed with value None.\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "/src/catboost/catboost/private/libs/algo/tensor_search_helpers.cpp:99: This should be unreachable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n\u001b[1;32m     27\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     30\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m     31\u001b[0m best_model \u001b[38;5;241m=\u001b[39m CatBoostClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      9\u001b[0m param \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m),\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_strength\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_strength\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1e-8\u001b[39m, \u001b[38;5;241m1.0\u001b[39m),\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m CatBoostClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam, loss_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, eval_set\u001b[38;5;241m=\u001b[39m(X_test, y_test), early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     22\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     23\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/catboost/core.py:5201\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5199\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, cat_features, text_features, embedding_features, \u001b[38;5;28;01mNone\u001b[39;00m, sample_weight, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, baseline, use_best_model,\n\u001b[1;32m   5202\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[1;32m   5203\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[1;32m   5204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/catboost/core.py:2396\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2393\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2395\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2396\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train(\n\u001b[1;32m   2397\u001b[0m         train_pool,\n\u001b[1;32m   2398\u001b[0m         train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_sets\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   2399\u001b[0m         params,\n\u001b[1;32m   2400\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2401\u001b[0m         train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2402\u001b[0m     )\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2405\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/catboost/core.py:1776\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[38;5;241m.\u001b[39m_object \u001b[38;5;28;01mif\u001b[39;00m init_model \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1777\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4833\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4882\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: /src/catboost/catboost/private/libs/algo/tensor_search_helpers.cpp:99: This should be unreachable"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "X = df.drop([\"target\"], axis = 1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-8, 100),\n",
    "        'border_count': trial.suggest_int('border_count', 1, 255),\n",
    "        'bagging_temperature': trial.suggest_loguniform('bagging_temperature', 1.0, 100.0),\n",
    "        'random_strength': trial.suggest_loguniform('random_strength', 1e-8, 1.0),\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**param, loss_function='Logloss')\n",
    "    model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=50, verbose=100)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_model = CatBoostClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=50, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    100192\n",
      "           1       0.65      0.01      0.01      3731\n",
      "\n",
      "    accuracy                           0.96    103923\n",
      "   macro avg       0.80      0.50      0.50    103923\n",
      "weighted avg       0.95      0.96      0.95    103923\n",
      "\n",
      "Precision: 0.6451612903225806\n",
      "Recall: 0.005360493165371214\n",
      "ROC AUC: 0.7381234061157389\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = best_model.predict_proba(X_test)\n",
    "y_pred = best_model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {classification_report(y_test, y_pred)}')\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba.ravel()[1::2])\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'ROC AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категориальные фичи "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artem cat features \n",
    "cat_features_tmp = ['feature5','feature6','feature7','feature9','feature74','feature85','feature96','feature106','feature117','feature127','feature138','feature150','feature163','feature174','feature215','feature293','feature343','feature344','feature345','feature346','feature347','feature348','feature349','feature350','feature352','feature356','feature360','feature363','feature364','feature374','feature379','feature381','feature383','feature389','feature393','feature395','feature396','feature397','feature398','feature399','feature400','feature401','feature402','feature403','feature404','feature408','feature409','feature410','feature411','feature412','feature413','feature415','feature416','feature417','feature419','feature421','feature422','feature425','feature427','feature428','feature430','feature431','feature432','feature436','feature437','feature438','feature439','feature441','feature442','feature443','feature444','feature445','feature446','feature447','feature448','feature449','feature450','feature452','feature453','feature454','feature459','feature460','feature463','feature465','feature466','feature472','feature474','feature475','feature476','feature477','feature478','feature479','feature480','feature481','feature483','feature485','feature486','feature488','feature490','feature491','feature492','feature493','feature494','feature497','feature498','feature499','feature500','feature501','feature502','feature504','feature505','feature508','feature509','feature510','feature512','feature513','feature514','feature515','feature516','feature517','feature519','feature520','feature521','feature524','feature525','feature526','feature527','feature528','feature534','feature535','feature538','feature539','feature541','feature542','feature543','feature544','feature547','feature548','feature549','feature550','feature552','feature553','feature554','feature557','feature558','feature559','feature560','feature577','feature580','feature581','feature594','feature596','feature597','feature598','feature599','feature600','feature601','feature602','feature604','feature606','feature608','feature609','feature610','feature611','feature612','feature613','feature616','feature617','feature619','feature620','feature621','feature622','feature631','feature634','feature639','feature644','feature647','feature650','feature654','feature660','feature664','feature666','feature668','feature672','feature673','feature682','feature692','feature695','feature698','feature705','feature712','feature740','feature741','feature743','feature744','feature746','feature747','feature750','feature751','feature753','feature754','feature757','feature758','feature760','feature763','feature766','feature767','feature769','feature770','feature771','feature773','feature776','feature777','feature786','feature787','feature788','feature789','feature790','feature791','feature792','feature794','feature795','feature796','feature797','feature800','feature803','feature804','feature805','feature811','feature812','feature813','feature814','feature815','feature835','feature838','feature842','feature843','feature845','feature851','feature853','feature855','feature857','feature861','feature863','feature864','feature866','feature868','feature870','feature873','feature875','feature877','feature879','feature881','feature884','feature887','feature927','feature928','feature929','feature930','feature931','feature932','feature937','feature991','feature992','feature993','feature994','feature995','feature996','feature997','feature998','feature999','feature1000','feature1003','feature1062','feature1063','feature1064','feature1065','feature1066','feature1068','feature1069','feature1070','feature1071','feature1072','feature1073','feature1074','feature1075','feature1076']\n",
    "cat_features = [feature for feature in cat_features_tmp if feature in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = [col for col in df.columns if df[col].nunique() < 5 and col != \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert cats to string\n",
    "for col in cat_features:\n",
    "    df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6779823\ttest: 0.6779615\tbest: 0.6779615 (0)\ttotal: 793ms\tremaining: 13m 11s\n",
      "100:\tlearn: 0.1840523\ttest: 0.1828898\tbest: 0.1828898 (100)\ttotal: 1m 49s\tremaining: 16m 12s\n",
      "200:\tlearn: 0.1466391\ttest: 0.1459123\tbest: 0.1459123 (200)\ttotal: 4m 29s\tremaining: 17m 52s\n",
      "300:\tlearn: 0.1403589\ttest: 0.1404598\tbest: 0.1404598 (300)\ttotal: 7m 31s\tremaining: 17m 28s\n",
      "400:\tlearn: 0.1382218\ttest: 0.1390445\tbest: 0.1390445 (400)\ttotal: 10m 19s\tremaining: 15m 25s\n",
      "500:\tlearn: 0.1370145\ttest: 0.1384657\tbest: 0.1384657 (500)\ttotal: 13m 15s\tremaining: 13m 11s\n",
      "600:\tlearn: 0.1361270\ttest: 0.1381147\tbest: 0.1381147 (600)\ttotal: 16m 29s\tremaining: 10m 56s\n",
      "700:\tlearn: 0.1354130\ttest: 0.1378616\tbest: 0.1378616 (700)\ttotal: 19m 45s\tremaining: 8m 25s\n",
      "800:\tlearn: 0.1348415\ttest: 0.1377058\tbest: 0.1377058 (800)\ttotal: 22m 56s\tremaining: 5m 41s\n",
      "900:\tlearn: 0.1343423\ttest: 0.1375738\tbest: 0.1375738 (900)\ttotal: 26m 1s\tremaining: 2m 51s\n",
      "999:\tlearn: 0.1339338\ttest: 0.1374693\tbest: 0.1374693 (999)\ttotal: 29m 7s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1374692781\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f1625c6cb50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop([\"target\"], axis = 1)\n",
    "y = df['target']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "model = CatBoostClassifier(iterations=1000, learning_rate=0.01, depth=8, loss_function='Logloss', cat_features=cat_features)\n",
    "model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature1004': 10.25550868976953,\n",
       " 'feature341': 5.448038390055345,\n",
       " 'feature318': 5.088408990697241,\n",
       " 'feature1000': 3.4621059234682305,\n",
       " 'feature994': 2.8880895645245,\n",
       " 'feature988': 2.589907079047815,\n",
       " 'feature920': 2.2319737769760652,\n",
       " 'feature210': 2.2288415732108433,\n",
       " 'feature356': 2.068587209501762,\n",
       " 'feature951': 2.014806758640155,\n",
       " 'feature320': 1.9601388914492945,\n",
       " 'feature208': 1.9003488756101612,\n",
       " 'feature713': 1.8027410623113953,\n",
       " 'feature936': 1.7247850117706516,\n",
       " 'feature942': 1.6868011865573591,\n",
       " 'feature922': 1.6207836059054634,\n",
       " 'feature950': 1.6150634588144794,\n",
       " 'feature357': 1.5422446849839793,\n",
       " 'feature349': 1.4763411804980442,\n",
       " 'feature941': 1.3130462302408705,\n",
       " 'feature935': 1.1653183636486504,\n",
       " 'feature444': 1.1559362876802721,\n",
       " 'feature783': 1.1156465260760717,\n",
       " 'feature940': 1.106815295659792,\n",
       " 'feature1': 1.100492397898269,\n",
       " 'feature551': 1.0996554580530191,\n",
       " 'feature990': 1.077964538732958,\n",
       " 'feature191': 1.0667436536315469,\n",
       " 'feature534': 0.9984382454180409,\n",
       " 'feature189': 0.9181077806885183,\n",
       " 'feature991': 0.8817346391293551,\n",
       " 'feature548': 0.8489602491121387,\n",
       " 'feature985': 0.7133647044445115,\n",
       " 'feature192': 0.6725147210086261,\n",
       " 'feature782': 0.6618755079087764,\n",
       " 'feature309': 0.658464593638097,\n",
       " 'feature1036': 0.618042639735045,\n",
       " 'feature715': 0.5686963797123062,\n",
       " 'feature405': 0.5583372862262294,\n",
       " 'feature946': 0.5503236001784962,\n",
       " 'feature561': 0.545534719320807,\n",
       " 'feature35': 0.5367503713571355,\n",
       " 'feature310': 0.510335189041953,\n",
       " 'feature193': 0.5042299226225314,\n",
       " 'feature472': 0.4936508515821071,\n",
       " 'feature938': 0.4793274151531238,\n",
       " 'feature350': 0.47629283044702847,\n",
       " 'feature508': 0.45559209383404525,\n",
       " 'feature118': 0.43665582517100254,\n",
       " 'feature1001': 0.426150217074164,\n",
       " 'feature989': 0.4022772988357118,\n",
       " 'feature997': 0.366676455153303,\n",
       " 'feature195': 0.35121256963658554,\n",
       " 'feature898': 0.3479673796864639,\n",
       " 'feature188': 0.34458280730169044,\n",
       " 'feature546': 0.33831605950921273,\n",
       " 'feature817': 0.3294402873719022,\n",
       " 'feature342': 0.32826812884323686,\n",
       " 'feature995': 0.310300728022466,\n",
       " 'feature122': 0.30899366245289805,\n",
       " 'feature998': 0.30048243572632494,\n",
       " 'feature91': 0.2918898125172228,\n",
       " 'feature287': 0.2912629792707948,\n",
       " 'feature758': 0.2904610131624675,\n",
       " 'feature1069': 0.28995365236812526,\n",
       " 'feature934': 0.2881254112438703,\n",
       " 'feature916': 0.2773795123157568,\n",
       " 'feature94': 0.264331691159423,\n",
       " 'feature945': 0.25183016616619236,\n",
       " 'feature750': 0.2511195175731456,\n",
       " 'feature435': 0.24260889897896298,\n",
       " 'feature996': 0.23593097266025986,\n",
       " 'feature572': 0.2331772654741231,\n",
       " 'feature4': 0.22816471196205199,\n",
       " 'feature450': 0.2206197000450692,\n",
       " 'feature182': 0.21677544077128758,\n",
       " 'feature187': 0.21459258899704928,\n",
       " 'feature999': 0.2066899593197976,\n",
       " 'feature947': 0.20169825592984558,\n",
       " 'feature282': 0.16995810321961557,\n",
       " 'feature446': 0.167707650583327,\n",
       " 'feature755': 0.1607925974837391,\n",
       " 'feature928': 0.1585655186505598,\n",
       " 'feature141': 0.15698390803463189,\n",
       " 'feature917': 0.15499202386550193,\n",
       " 'feature67': 0.1529808645177201,\n",
       " 'feature18': 0.15181019759438938,\n",
       " 'feature103': 0.14792732000199607,\n",
       " 'feature620': 0.14149936125284132,\n",
       " 'feature533': 0.13963674994753228,\n",
       " 'feature180': 0.13843626201297704,\n",
       " 'feature454': 0.13778957350589252,\n",
       " 'feature939': 0.1323814114430079,\n",
       " 'feature862': 0.12770490595997355,\n",
       " 'feature358': 0.12424593996509176,\n",
       " 'feature469': 0.12149123281968456,\n",
       " 'feature154': 0.12059367067038314,\n",
       " 'feature491': 0.12010669886123512,\n",
       " 'feature553': 0.11924814721044237,\n",
       " 'feature490': 0.11766658434171419,\n",
       " 'feature552': 0.10896989912027503,\n",
       " 'feature226': 0.10542419616697717,\n",
       " 'feature233': 0.10329601489007662,\n",
       " 'feature937': 0.1010719571677707,\n",
       " 'feature987': 0.09937383169674233,\n",
       " 'feature470': 0.0985335132417434,\n",
       " 'feature918': 0.09724194600741083,\n",
       " 'feature43': 0.09533595948733435,\n",
       " 'feature156': 0.09469352953954487,\n",
       " 'feature871': 0.09456963641955239,\n",
       " 'feature501': 0.09354428044194606,\n",
       " 'feature510': 0.09347530117343192,\n",
       " 'feature194': 0.09167001314865307,\n",
       " 'feature109': 0.09164696872633793,\n",
       " 'feature559': 0.09139964089295997,\n",
       " 'feature540': 0.09104337096418899,\n",
       " 'feature763': 0.09029660005806052,\n",
       " 'feature322': 0.08865929340369988,\n",
       " 'feature121': 0.08861300799075097,\n",
       " 'feature488': 0.08830862669396017,\n",
       " 'feature927': 0.08657468273495371,\n",
       " 'feature367': 0.08456272124713737,\n",
       " 'feature532': 0.0844304024068403,\n",
       " 'feature260': 0.08377219154836076,\n",
       " 'feature919': 0.08363632996549229,\n",
       " 'feature37': 0.08361034548338554,\n",
       " 'feature107': 0.08254314493884576,\n",
       " 'feature181': 0.08233268507309156,\n",
       " 'feature564': 0.08200821229499271,\n",
       " 'feature427': 0.08195569599094332,\n",
       " 'feature504': 0.07870999474913316,\n",
       " 'feature200': 0.07755679021994802,\n",
       " 'feature721': 0.07679480972971098,\n",
       " 'feature340': 0.07612269053605644,\n",
       " 'feature172': 0.07599800483057394,\n",
       " 'feature1035': 0.07585398446363822,\n",
       " 'feature88': 0.07535020946604228,\n",
       " 'feature876': 0.0738802455948495,\n",
       " 'feature475': 0.07279124576710798,\n",
       " 'feature395': 0.07108736059110973,\n",
       " 'feature47': 0.07073331228051626,\n",
       " 'feature843': 0.0705163266653485,\n",
       " 'feature9': 0.07026309809564506,\n",
       " 'feature370': 0.0698798053913595,\n",
       " 'feature527': 0.06941300554197082,\n",
       " 'feature930': 0.06938240442488304,\n",
       " 'feature153': 0.06934149048275919,\n",
       " 'feature316': 0.06920827574100738,\n",
       " 'feature810': 0.06904191675216191,\n",
       " 'feature777': 0.06767101929903556,\n",
       " 'feature288': 0.06760044007932699,\n",
       " 'feature101': 0.06716774645617586,\n",
       " 'feature1056': 0.06670982877792869,\n",
       " 'feature751': 0.06573184072025491,\n",
       " 'feature554': 0.06416687715144836,\n",
       " 'feature929': 0.06269931887716998,\n",
       " 'feature893': 0.06266048337274935,\n",
       " 'feature754': 0.06232418801908877,\n",
       " 'feature535': 0.06192267872475073,\n",
       " 'feature509': 0.06186204349713154,\n",
       " 'feature24': 0.06178934303400099,\n",
       " 'feature799': 0.06116611961378118,\n",
       " 'feature884': 0.0606582365105969,\n",
       " 'feature3': 0.06023400171697786,\n",
       " 'feature149': 0.05986291451261682,\n",
       " 'feature98': 0.059198915501928316,\n",
       " 'feature497': 0.058895745179721806,\n",
       " 'feature137': 0.05889287208319285,\n",
       " 'feature185': 0.05857417241481109,\n",
       " 'feature183': 0.05855729362134547,\n",
       " 'feature800': 0.05841497274487983,\n",
       " 'feature412': 0.05831940298539127,\n",
       " 'feature855': 0.05780797657047056,\n",
       " 'feature46': 0.05635560734931248,\n",
       " 'feature538': 0.05619591592289005,\n",
       " 'feature136': 0.05496733930736134,\n",
       " 'feature529': 0.05485087659170899,\n",
       " 'feature539': 0.05482377853607776,\n",
       " 'feature304': 0.05384277720222577,\n",
       " 'feature688': 0.05377439133144273,\n",
       " 'feature792': 0.05278849935976024,\n",
       " 'feature152': 0.052475133360582245,\n",
       " 'feature932': 0.051367105640727766,\n",
       " 'feature268': 0.049496947938438944,\n",
       " 'feature712': 0.049493116219382016,\n",
       " 'feature346': 0.04919395987003267,\n",
       " 'feature547': 0.04845995080140182,\n",
       " 'feature923': 0.048422203952514085,\n",
       " 'feature124': 0.048360200821975646,\n",
       " 'feature562': 0.04827787205228878,\n",
       " 'feature518': 0.04766881735832207,\n",
       " 'feature7': 0.047473828611760034,\n",
       " 'feature543': 0.04747270403389791,\n",
       " 'feature343': 0.04578444459048035,\n",
       " 'feature25': 0.045780462174715444,\n",
       " 'feature155': 0.04508432515609255,\n",
       " 'feature120': 0.044276564379856616,\n",
       " 'feature290': 0.04420482055090589,\n",
       " 'feature890': 0.04331023327934364,\n",
       " 'feature891': 0.04302003512217146,\n",
       " 'feature145': 0.04246436244551538,\n",
       " 'feature2': 0.04222649305729169,\n",
       " 'id': 0.041782643006392464,\n",
       " 'feature811': 0.04154119021080905,\n",
       " 'feature176': 0.04105564960070122,\n",
       " 'feature461': 0.04104453864086324,\n",
       " 'feature218': 0.04067501764206433,\n",
       " 'feature505': 0.04065937535085781,\n",
       " 'feature515': 0.040128947471534934,\n",
       " 'feature12': 0.03990110569453298,\n",
       " 'feature6': 0.0395948298001892,\n",
       " 'feature179': 0.03931723003000789,\n",
       " 'feature428': 0.03882423439971335,\n",
       " 'feature513': 0.03813256345381254,\n",
       " 'feature894': 0.03766312275932833,\n",
       " 'feature441': 0.03758849719109753,\n",
       " 'feature344': 0.037042219414298784,\n",
       " 'feature33': 0.036771084037121274,\n",
       " 'feature526': 0.03629251176639751,\n",
       " 'feature415': 0.03612450070155177,\n",
       " 'feature19': 0.03607955490117543,\n",
       " 'feature164': 0.03601546432517218,\n",
       " 'feature158': 0.0355819009377316,\n",
       " 'feature425': 0.03555093357935604,\n",
       " 'feature147': 0.035536511695253535,\n",
       " 'feature220': 0.0353436992346149,\n",
       " 'feature30': 0.0353338475946442,\n",
       " 'feature105': 0.03525158570084555,\n",
       " 'feature345': 0.03505511970976105,\n",
       " 'feature93': 0.034924044707548396,\n",
       " 'feature485': 0.03458814709833532,\n",
       " 'feature139': 0.03369267455860576,\n",
       " 'feature1042': 0.033096340872389315,\n",
       " 'feature666': 0.03283954990993249,\n",
       " 'feature429': 0.0323228029746991,\n",
       " 'feature451': 0.032026321973700325,\n",
       " 'feature493': 0.03148120086990275,\n",
       " 'feature58': 0.03146359869987827,\n",
       " 'feature764': 0.03137296342319625,\n",
       " 'feature851': 0.0311321803365195,\n",
       " 'feature651': 0.030935830234731166,\n",
       " 'feature62': 0.030575102255883783,\n",
       " 'feature776': 0.030555580216294044,\n",
       " 'feature163': 0.03008763656656761,\n",
       " 'feature161': 0.029977589104109616,\n",
       " 'feature448': 0.029624707264689874,\n",
       " 'feature815': 0.029605124307031765,\n",
       " 'feature99': 0.02951423039773078,\n",
       " 'feature525': 0.02940743541045121,\n",
       " 'feature452': 0.028588419621626084,\n",
       " 'feature492': 0.02836126461321812,\n",
       " 'feature215': 0.028068644643603598,\n",
       " 'feature175': 0.02793684353324572,\n",
       " 'feature557': 0.027918295588920297,\n",
       " 'feature772': 0.027715132544230758,\n",
       " 'feature530': 0.027198983812626955,\n",
       " 'feature793': 0.027070611614340868,\n",
       " 'feature500': 0.026963524233747767,\n",
       " 'feature178': 0.02670489301829283,\n",
       " 'feature393': 0.026483930983075082,\n",
       " 'feature861': 0.026197665694050444,\n",
       " 'feature753': 0.02619362862585263,\n",
       " 'feature399': 0.025848703605230984,\n",
       " 'feature143': 0.025435195574817843,\n",
       " 'feature869': 0.02530625246247985,\n",
       " 'feature173': 0.025291664819721824,\n",
       " 'feature177': 0.025207391614190035,\n",
       " 'feature102': 0.025105563975501427,\n",
       " 'feature1057': 0.024709851168390407,\n",
       " 'feature78': 0.0245895889871645,\n",
       " 'feature1059': 0.02441023511093244,\n",
       " 'feature503': 0.02431407874618715,\n",
       " 'feature781': 0.024095056955071553,\n",
       " 'feature507': 0.023893100980483573,\n",
       " 'feature45': 0.023656931439096095,\n",
       " 'feature112': 0.023389521970290414,\n",
       " 'feature531': 0.023310830132937346,\n",
       " 'feature849': 0.023125375658986723,\n",
       " 'feature749': 0.023060002097167628,\n",
       " 'feature820': 0.02238263493787623,\n",
       " 'feature528': 0.022049683975692583,\n",
       " 'feature355': 0.021503703983513096,\n",
       " 'feature170': 0.021449023539922,\n",
       " 'feature286': 0.02143635252930465,\n",
       " 'feature110': 0.0214326176217872,\n",
       " 'feature489': 0.021220028871366974,\n",
       " 'feature498': 0.020980704273446824,\n",
       " 'feature675': 0.020930785229689663,\n",
       " 'feature587': 0.020483052806745606,\n",
       " 'feature453': 0.020372717491082964,\n",
       " 'feature264': 0.020184139099400922,\n",
       " 'feature550': 0.020137885352905047,\n",
       " 'feature366': 0.019951487746249018,\n",
       " 'feature353': 0.019934916210088825,\n",
       " 'feature857': 0.0194948696970347,\n",
       " 'feature92': 0.019396630251484276,\n",
       " 'feature517': 0.0191382060987703,\n",
       " 'feature459': 0.01912069473730713,\n",
       " 'feature162': 0.019073628269207478,\n",
       " 'feature157': 0.019042953026687588,\n",
       " 'feature447': 0.01901658156112141,\n",
       " 'feature773': 0.01866240158767789,\n",
       " 'feature757': 0.018597850322237087,\n",
       " 'feature354': 0.018345955147949584,\n",
       " 'feature885': 0.018331990716525123,\n",
       " 'feature925': 0.018284289514910027,\n",
       " 'feature114': 0.018249222041016262,\n",
       " 'feature199': 0.01818120945259746,\n",
       " 'feature5': 0.018143998849274635,\n",
       " 'feature502': 0.017881667513464535,\n",
       " 'feature104': 0.01784496176841006,\n",
       " 'feature506': 0.017674211840434693,\n",
       " 'feature41': 0.017378010148048018,\n",
       " 'feature413': 0.01737140584935815,\n",
       " 'feature359': 0.01722812295877962,\n",
       " 'feature924': 0.017141711406463273,\n",
       " 'feature667': 0.017125461273413616,\n",
       " 'feature541': 0.017100559754454004,\n",
       " 'feature174': 0.01708934752163127,\n",
       " 'feature495': 0.01692303039609898,\n",
       " 'feature85': 0.016827995778878363,\n",
       " 'feature335': 0.016793313251340352,\n",
       " 'feature202': 0.016731741349266027,\n",
       " 'feature717': 0.01657195288136635,\n",
       " 'feature874': 0.01645878856672359,\n",
       " 'feature872': 0.015913811621916622,\n",
       " 'feature306': 0.01586605136586818,\n",
       " 'feature280': 0.015848225672904042,\n",
       " 'feature897': 0.015688823012832344,\n",
       " 'feature778': 0.01564332154679203,\n",
       " 'feature411': 0.015318192469247477,\n",
       " 'feature439': 0.015230719880310732,\n",
       " 'feature442': 0.015159944468428384,\n",
       " 'feature281': 0.01512556424544217,\n",
       " 'feature1043': 0.01491022513076639,\n",
       " 'feature108': 0.014808327160640965,\n",
       " 'feature690': 0.014142611611318872,\n",
       " 'feature369': 0.013842879916531292,\n",
       " 'feature599': 0.013689603579930614,\n",
       " 'feature521': 0.013468234058308978,\n",
       " 'feature617': 0.013078628519984696,\n",
       " 'feature75': 0.013000454177461476,\n",
       " 'feature813': 0.012929627799433073,\n",
       " 'feature437': 0.01292749618630987,\n",
       " 'feature385': 0.012686840686272509,\n",
       " 'feature986': 0.012569848619719276,\n",
       " 'feature558': 0.012542924062755556,\n",
       " 'feature151': 0.012491644003921836,\n",
       " 'feature234': 0.012435920465908846,\n",
       " 'feature44': 0.012401133161586387,\n",
       " 'feature100': 0.012095032469119278,\n",
       " 'feature471': 0.012087274256672994,\n",
       " 'feature545': 0.01194202673381509,\n",
       " 'feature926': 0.011915685515256088,\n",
       " 'feature148': 0.011889991869660678,\n",
       " 'feature334': 0.011853971198062127,\n",
       " 'feature795': 0.011535350756308151,\n",
       " 'feature842': 0.011404109372654089,\n",
       " 'feature111': 0.011063213955202733,\n",
       " 'feature197': 0.01105005207023081,\n",
       " 'feature113': 0.010975709420866295,\n",
       " 'feature656': 0.010841582487258174,\n",
       " 'feature854': 0.010802503690359856,\n",
       " 'feature184': 0.010676736441630202,\n",
       " 'feature473': 0.010648219182401239,\n",
       " 'feature171': 0.010596840647917233,\n",
       " 'feature140': 0.010441794542151854,\n",
       " 'feature410': 0.010333791423571452,\n",
       " 'feature829': 0.010282794806850236,\n",
       " 'feature434': 0.010083500446302256,\n",
       " 'feature38': 0.010083191481486632,\n",
       " 'feature465': 0.009941801509039618,\n",
       " 'feature203': 0.0097425752769484,\n",
       " 'feature888': 0.009736058771597215,\n",
       " 'feature146': 0.009641584076832474,\n",
       " 'feature693': 0.009588637505386693,\n",
       " 'feature695': 0.009439296090829462,\n",
       " 'feature291': 0.00943638810596298,\n",
       " 'feature770': 0.009385005984267995,\n",
       " 'feature921': 0.009329533513066122,\n",
       " 'feature305': 0.009105848603298104,\n",
       " 'feature95': 0.009001256702244977,\n",
       " 'feature677': 0.008970425826784967,\n",
       " 'feature716': 0.008790705576801469,\n",
       " 'feature797': 0.008683942416114658,\n",
       " 'feature48': 0.008623918632995112,\n",
       " 'feature87': 0.008459105084170224,\n",
       " 'feature277': 0.00835486017506728,\n",
       " 'feature409': 0.008324134451363345,\n",
       " 'feature542': 0.008287079677175608,\n",
       " 'feature52': 0.008132575201267539,\n",
       " 'feature71': 0.008088434835347309,\n",
       " 'feature674': 0.008021581316936905,\n",
       " 'feature133': 0.007736557131156545,\n",
       " 'feature293': 0.00753815033367868,\n",
       " 'feature331': 0.0075186672439167416,\n",
       " 'feature125': 0.007509313142444213,\n",
       " 'feature588': 0.007090475933243051,\n",
       " 'feature856': 0.007017846023016795,\n",
       " 'feature476': 0.007009308758287904,\n",
       " 'feature116': 0.00695510794838763,\n",
       " 'feature96': 0.006888957314949326,\n",
       " 'feature186': 0.006772744790237637,\n",
       " 'feature463': 0.006692585308631875,\n",
       " 'feature462': 0.006638945350439945,\n",
       " 'feature892': 0.0065254678889819645,\n",
       " 'feature845': 0.0063397784121076075,\n",
       " 'feature311': 0.006076029713893263,\n",
       " 'feature66': 0.006035701880611674,\n",
       " 'feature244': 0.005898456431288084,\n",
       " 'feature563': 0.005887434478706719,\n",
       " 'feature785': 0.005776254477340908,\n",
       " 'feature123': 0.005732472432669759,\n",
       " 'feature790': 0.005701646208194084,\n",
       " 'feature308': 0.005656236925886787,\n",
       " 'feature689': 0.005491266935601478,\n",
       " 'feature289': 0.005453933459479896,\n",
       " 'feature217': 0.005435277913681149,\n",
       " 'feature63': 0.005333184407011532,\n",
       " 'feature759': 0.005272488436882224,\n",
       " 'feature49': 0.005205879697902649,\n",
       " 'feature275': 0.005115394590119057,\n",
       " 'feature89': 0.005038473360937063,\n",
       " 'feature56': 0.0049852628295151856,\n",
       " 'feature97': 0.0048713412851127845,\n",
       " 'feature86': 0.004784356496011859,\n",
       " 'feature73': 0.004641266172124182,\n",
       " 'feature455': 0.004630006343354197,\n",
       " 'feature668': 0.004561298728890478,\n",
       " 'feature804': 0.004523087294105507,\n",
       " 'feature779': 0.004470319466422551,\n",
       " 'feature769': 0.004382385969250373,\n",
       " 'feature169': 0.0042092887130618945,\n",
       " 'feature833': 0.0041848586210355325,\n",
       " 'feature296': 0.0040004475239307485,\n",
       " 'feature401': 0.003759645674885171,\n",
       " 'feature279': 0.003679531213539464,\n",
       " 'feature830': 0.0036791757564184633,\n",
       " 'feature297': 0.0036178856143453805,\n",
       " 'feature780': 0.0036089112050812122,\n",
       " 'feature642': 0.0035809702584407277,\n",
       " 'feature649': 0.0035740048474399017,\n",
       " 'feature873': 0.0035314535638533147,\n",
       " 'feature426': 0.003521632244909305,\n",
       " 'feature705': 0.003507055940242467,\n",
       " 'feature805': 0.0034781842522860367,\n",
       " 'feature555': 0.003458237770817795,\n",
       " 'feature72': 0.0033153536538786514,\n",
       " 'feature386': 0.0033110651509865906,\n",
       " 'feature165': 0.003269315220931711,\n",
       " 'feature307': 0.00318880696234398,\n",
       " 'feature516': 0.0030688576667273378,\n",
       " 'feature273': 0.0029859732342501725,\n",
       " 'feature880': 0.002980827362349376,\n",
       " 'feature74': 0.002900553915503096,\n",
       " 'feature390': 0.002895514910871932,\n",
       " 'feature408': 0.002708779152507958,\n",
       " 'feature230': 0.0026234587529121597,\n",
       " 'feature1050': 0.002559275856413433,\n",
       " 'feature440': 0.002535686186161963,\n",
       " 'feature61': 0.002534563375651467,\n",
       " 'feature77': 0.0024703425109754923,\n",
       " 'feature650': 0.0024086286801892486,\n",
       " 'feature216': 0.0024078763125788974,\n",
       " 'feature303': 0.002383238190339114,\n",
       " 'feature64': 0.002342912425528232,\n",
       " 'feature83': 0.0023178634590064586,\n",
       " 'feature522': 0.002215027599203401,\n",
       " 'feature329': 0.0021500709233407463,\n",
       " 'feature336': 0.0021370816737734046,\n",
       " 'feature431': 0.002064190439113896,\n",
       " 'feature752': 0.002047375290481023,\n",
       " 'feature278': 0.0019470394731517335,\n",
       " 'feature205': 0.0018446554077864033,\n",
       " 'feature791': 0.0018332547698555663,\n",
       " 'feature332': 0.001814130127630116,\n",
       " 'feature84': 0.0018035484796973553,\n",
       " 'feature328': 0.0017661848229247644,\n",
       " 'feature831': 0.0017598329176667234,\n",
       " 'feature1066': 0.0017442394947187,\n",
       " 'feature352': 0.0017224682142045636,\n",
       " 'feature82': 0.0014138517392704106,\n",
       " 'feature1051': 0.0014068450632620342,\n",
       " 'feature870': 0.001255446914952527,\n",
       " 'feature225': 0.0011980157032964376,\n",
       " 'feature648': 0.0011429263182619002,\n",
       " 'feature300': 0.0011137908698323168,\n",
       " 'feature841': 0.001043761196883928,\n",
       " 'feature325': 0.001035726548994264,\n",
       " 'feature229': 0.0010201556377712384,\n",
       " 'feature768': 0.000980326158213805,\n",
       " 'feature644': 0.000916967068483406,\n",
       " 'feature31': 0.0008744689162723352,\n",
       " 'feature295': 0.0008153177140732395,\n",
       " 'feature1049': 0.000799186043534643,\n",
       " 'feature416': 0.0007769898778585663,\n",
       " 'feature423': 0.0006764532319359446,\n",
       " 'feature682': 0.0005632010766004885,\n",
       " 'feature524': 0.0005136038604334184,\n",
       " 'feature59': 0.0004577833889991653,\n",
       " 'feature76': 0.00038041099627550765,\n",
       " 'feature394': 0.00037925110241560144,\n",
       " 'feature227': 0.0003417539869419724,\n",
       " 'feature294': 0.0002690434459848139,\n",
       " 'feature420': 0.000266161247328096,\n",
       " 'feature321': 0.0002479656371059289,\n",
       " 'feature391': 0.0002447340387826751,\n",
       " 'feature1054': 0.00023718043201596492,\n",
       " 'feature117': 0.00022935096705016306,\n",
       " 'feature333': 0.00021029689505049719,\n",
       " 'feature685': 0.00019519887213053147,\n",
       " 'feature276': 0.00017211696563353422,\n",
       " 'feature70': 0.00017152136621487066,\n",
       " 'feature60': 7.879603442122933e-05,\n",
       " 'feature166': 5.475049557073896e-05,\n",
       " 'feature1068': 4.751493750835212e-05,\n",
       " 'feature22': 0.0,\n",
       " 'feature23': 0.0,\n",
       " 'feature26': 0.0,\n",
       " 'feature36': 0.0,\n",
       " 'feature42': 0.0,\n",
       " 'feature65': 0.0,\n",
       " 'feature79': 0.0,\n",
       " 'feature80': 0.0,\n",
       " 'feature106': 0.0,\n",
       " 'feature115': 0.0,\n",
       " 'feature127': 0.0,\n",
       " 'feature128': 0.0,\n",
       " 'feature138': 0.0,\n",
       " 'feature150': 0.0,\n",
       " 'feature167': 0.0,\n",
       " 'feature168': 0.0,\n",
       " 'feature196': 0.0,\n",
       " 'feature204': 0.0,\n",
       " 'feature214': 0.0,\n",
       " 'feature224': 0.0,\n",
       " 'feature231': 0.0,\n",
       " 'feature232': 0.0,\n",
       " 'feature243': 0.0,\n",
       " 'feature274': 0.0,\n",
       " 'feature285': 0.0,\n",
       " 'feature298': 0.0,\n",
       " 'feature299': 0.0,\n",
       " 'feature301': 0.0,\n",
       " 'feature302': 0.0,\n",
       " 'feature324': 0.0,\n",
       " 'feature330': 0.0,\n",
       " 'feature337': 0.0,\n",
       " 'feature338': 0.0,\n",
       " 'feature339': 0.0,\n",
       " 'feature384': 0.0,\n",
       " 'feature387': 0.0,\n",
       " 'feature388': 0.0,\n",
       " 'feature392': 0.0,\n",
       " 'feature400': 0.0,\n",
       " 'feature404': 0.0,\n",
       " 'feature417': 0.0,\n",
       " 'feature418': 0.0,\n",
       " 'feature433': 0.0,\n",
       " 'feature456': 0.0,\n",
       " 'feature464': 0.0,\n",
       " 'feature468': 0.0,\n",
       " 'feature478': 0.0,\n",
       " 'feature536': 0.0,\n",
       " 'feature537': 0.0,\n",
       " 'feature544': 0.0,\n",
       " 'feature556': 0.0,\n",
       " 'feature565': 0.0,\n",
       " 'feature566': 0.0,\n",
       " 'feature567': 0.0,\n",
       " 'feature568': 0.0,\n",
       " 'feature570': 0.0,\n",
       " 'feature571': 0.0,\n",
       " 'feature574': 0.0,\n",
       " 'feature575': 0.0,\n",
       " 'feature578': 0.0,\n",
       " 'feature597': 0.0,\n",
       " 'feature616': 0.0,\n",
       " 'feature619': 0.0,\n",
       " 'feature622': 0.0,\n",
       " 'feature624': 0.0,\n",
       " 'feature627': 0.0,\n",
       " 'feature628': 0.0,\n",
       " 'feature630': 0.0,\n",
       " 'feature631': 0.0,\n",
       " 'feature633': 0.0,\n",
       " 'feature634': 0.0,\n",
       " 'feature637': 0.0,\n",
       " 'feature639': 0.0,\n",
       " 'feature640': 0.0,\n",
       " 'feature652': 0.0,\n",
       " 'feature653': 0.0,\n",
       " 'feature654': 0.0,\n",
       " 'feature657': 0.0,\n",
       " 'feature658': 0.0,\n",
       " 'feature659': 0.0,\n",
       " 'feature660': 0.0,\n",
       " 'feature662': 0.0,\n",
       " 'feature664': 0.0,\n",
       " 'feature665': 0.0,\n",
       " 'feature670': 0.0,\n",
       " 'feature671': 0.0,\n",
       " 'feature672': 0.0,\n",
       " 'feature680': 0.0,\n",
       " 'feature684': 0.0,\n",
       " 'feature687': 0.0,\n",
       " 'feature692': 0.0,\n",
       " 'feature694': 0.0,\n",
       " 'feature697': 0.0,\n",
       " 'feature698': 0.0,\n",
       " 'feature699': 0.0,\n",
       " 'feature700': 0.0,\n",
       " 'feature701': 0.0,\n",
       " 'feature703': 0.0,\n",
       " 'feature704': 0.0,\n",
       " 'feature706': 0.0,\n",
       " 'feature707': 0.0,\n",
       " 'feature708': 0.0,\n",
       " 'feature709': 0.0,\n",
       " 'feature711': 0.0,\n",
       " 'feature719': 0.0,\n",
       " 'feature720': 0.0,\n",
       " 'feature723': 0.0,\n",
       " 'feature726': 0.0,\n",
       " 'feature729': 0.0,\n",
       " 'feature732': 0.0,\n",
       " 'feature735': 0.0,\n",
       " 'feature738': 0.0,\n",
       " 'feature741': 0.0,\n",
       " 'feature748': 0.0,\n",
       " 'feature762': 0.0,\n",
       " 'feature775': 0.0,\n",
       " 'feature786': 0.0,\n",
       " 'feature787': 0.0,\n",
       " 'feature788': 0.0,\n",
       " 'feature794': 0.0,\n",
       " 'feature796': 0.0,\n",
       " 'feature821': 0.0,\n",
       " 'feature825': 0.0,\n",
       " 'feature832': 0.0,\n",
       " 'feature837': 0.0,\n",
       " 'feature844': 0.0,\n",
       " 'feature878': 0.0,\n",
       " 'feature879': 0.0,\n",
       " 'feature886': 0.0,\n",
       " 'feature887': 0.0,\n",
       " 'feature1037': 0.0,\n",
       " 'feature1052': 0.0,\n",
       " 'feature1055': 0.0,\n",
       " 'feature1063': 0.0,\n",
       " 'feature1064': 0.0,\n",
       " 'feature1065': 0.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_weights = {feature: weight for feature, weight in zip(X.columns, model.feature_importances_)}\n",
    "dict(sorted(feature_weights.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     75146\n",
      "           1       0.60      0.00      0.01      2797\n",
      "\n",
      "    accuracy                           0.96     77943\n",
      "   macro avg       0.78      0.50      0.49     77943\n",
      "weighted avg       0.95      0.96      0.95     77943\n",
      "\n",
      "Precision: 0.6\n",
      "Recall: 0.0032177332856632105\n",
      "ROC AUC: 0.7418843837886655\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict_proba(X_test)\n",
    "y_pred = model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {classification_report(y_test, y_pred)}')\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba.ravel()[1::2])\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'ROC AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отбор по feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561, 749)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_weights = {feature: weight for feature, weight in zip(X.columns, model.feature_importances_)}\n",
    "selected_features = [k for k, v in feature_weights.items() if v > 0]\n",
    "f\" отобралось {len(selected_features)} фич из {len(feature_weights)} \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6777413\ttest: 0.6777841\tbest: 0.6777841 (0)\ttotal: 90.8ms\tremaining: 1m 30s\n",
      "100:\tlearn: 0.1816663\ttest: 0.1828781\tbest: 0.1828781 (100)\ttotal: 7.47s\tremaining: 1m 6s\n",
      "200:\tlearn: 0.1452007\ttest: 0.1475164\tbest: 0.1475164 (200)\ttotal: 15.5s\tremaining: 1m 1s\n",
      "300:\tlearn: 0.1393600\ttest: 0.1426631\tbest: 0.1426631 (300)\ttotal: 23.9s\tremaining: 55.6s\n",
      "400:\tlearn: 0.1374007\ttest: 0.1415068\tbest: 0.1415068 (400)\ttotal: 32.1s\tremaining: 48s\n",
      "500:\tlearn: 0.1361880\ttest: 0.1409738\tbest: 0.1409738 (500)\ttotal: 39.8s\tremaining: 39.7s\n",
      "600:\tlearn: 0.1353036\ttest: 0.1406660\tbest: 0.1406660 (600)\ttotal: 47.4s\tremaining: 31.5s\n",
      "700:\tlearn: 0.1345623\ttest: 0.1404493\tbest: 0.1404493 (700)\ttotal: 54.8s\tremaining: 23.4s\n",
      "800:\tlearn: 0.1338575\ttest: 0.1402639\tbest: 0.1402639 (800)\ttotal: 1m 2s\tremaining: 15.5s\n",
      "900:\tlearn: 0.1332664\ttest: 0.1401084\tbest: 0.1401084 (900)\ttotal: 1m 9s\tremaining: 7.63s\n",
      "999:\tlearn: 0.1327011\ttest: 0.1399924\tbest: 0.1399924 (999)\ttotal: 1m 16s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1399924205\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fa3d0084310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sel = df[selected_features]\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = CatBoostClassifier(iterations=1000, learning_rate=0.01, depth=8, loss_function='Logloss')\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=50, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    100192\n",
      "           1       0.77      0.00      0.01      3731\n",
      "\n",
      "    accuracy                           0.96    103923\n",
      "   macro avg       0.87      0.50      0.49    103923\n",
      "weighted avg       0.96      0.96      0.95    103923\n",
      "\n",
      "Precision: 0.7692307692307693\n",
      "Recall: 0.002680246582685607\n",
      "ROC AUC: 0.7406038834812663\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict_proba(X_test)\n",
    "y_pred = model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {classification_report(y_test, y_pred)}')\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba.ravel()[1::2])\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'ROC AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561, 749)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_weights = {feature: weight for feature, weight in zip(X.columns, model.feature_importances_)}\n",
    "selected_features = [k for k, v in dict(sorted(feature_weights.items(), key=lambda item: item[1], reverse=True)).items() if v > 0]\n",
    "len(selected_features), len(feature_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0.03807066600838285,\n",
       " 'sample_ml_new': 0.0,\n",
       " 'feature1': 1.2488766221397836,\n",
       " 'feature2': 0.1598991122892265,\n",
       " 'feature3': 0.08070800397400199,\n",
       " 'feature4': 0.1116965235891375,\n",
       " 'feature5': 0.06052095579327117,\n",
       " 'feature6': 0.18210495553714393,\n",
       " 'feature7': 0.05118671231306596,\n",
       " 'feature9': 0.09000518155062921,\n",
       " 'feature12': 0.07257652168078543,\n",
       " 'feature18': 0.13056974251327808,\n",
       " 'feature19': 0.0552117134006944,\n",
       " 'feature22': 0.016558461033134034,\n",
       " 'feature23': 2.685235435876654e-05,\n",
       " 'feature24': 0.0056580833675225805,\n",
       " 'feature25': 0.07387581848902283,\n",
       " 'feature26': 0.0,\n",
       " 'feature27': 3.734147911872943e-05,\n",
       " 'feature28': 0.00016417105350564678,\n",
       " 'feature30': 0.016597221193952943,\n",
       " 'feature31': 0.010995943441797522,\n",
       " 'feature33': 0.0,\n",
       " 'feature35': 0.45975151153987803,\n",
       " 'feature36': 0.008317434195305954,\n",
       " 'feature37': 0.09306898550918699,\n",
       " 'feature38': 0.0327386469618588,\n",
       " 'feature41': 0.035665957179934295,\n",
       " 'feature42': 0.02063912858843175,\n",
       " 'feature43': 0.242487277290389,\n",
       " 'feature44': 0.027557111323825125,\n",
       " 'feature45': 0.028389131615013753,\n",
       " 'feature46': 0.09452776696251249,\n",
       " 'feature47': 0.08209947757134445,\n",
       " 'feature48': 0.009935400755015493,\n",
       " 'feature49': 0.0,\n",
       " 'feature52': 0.038925744364221526,\n",
       " 'feature56': 0.017953812016954937,\n",
       " 'feature58': 0.01167615419936226,\n",
       " 'feature59': 0.0047491913378913155,\n",
       " 'feature60': 0.0004690755089719242,\n",
       " 'feature61': 0.0018502262304755871,\n",
       " 'feature62': 0.01768618800327503,\n",
       " 'feature63': 0.014612405252060628,\n",
       " 'feature64': 0.019610680945302012,\n",
       " 'feature65': 0.00514373192384928,\n",
       " 'feature66': 0.00016689457846322204,\n",
       " 'feature67': 0.20206182274128265,\n",
       " 'feature68': 0.0,\n",
       " 'feature69': 0.0,\n",
       " 'feature70': 0.0005658120166045567,\n",
       " 'feature71': 0.008463401033530391,\n",
       " 'feature72': 0.008886814771138066,\n",
       " 'feature73': 0.005715281396294173,\n",
       " 'feature74': 0.0,\n",
       " 'feature75': 0.018936902603370692,\n",
       " 'feature76': 0.02196763291668201,\n",
       " 'feature77': 0.020019672850783224,\n",
       " 'feature78': 0.00604510422203216,\n",
       " 'feature79': 0.0,\n",
       " 'feature80': 0.002715943439604275,\n",
       " 'feature82': 0.0,\n",
       " 'feature83': 0.0073749364918020395,\n",
       " 'feature84': 0.004239058867895357,\n",
       " 'feature85': 0.005036695237676853,\n",
       " 'feature86': 0.026029229167583948,\n",
       " 'feature87': 0.01847114289683713,\n",
       " 'feature88': 0.08863972459808171,\n",
       " 'feature89': 0.1309464211467019,\n",
       " 'feature91': 0.13170928852487152,\n",
       " 'feature92': 0.0014799473714129608,\n",
       " 'feature93': 0.029458555235605387,\n",
       " 'feature94': 0.4170989085312432,\n",
       " 'feature95': 0.0014710467167112112,\n",
       " 'feature96': 0.04010661653929338,\n",
       " 'feature97': 0.011677646943418439,\n",
       " 'feature98': 0.023029226183417406,\n",
       " 'feature99': 0.026725610020262528,\n",
       " 'feature100': 0.013048865142512871,\n",
       " 'feature101': 0.07580223711115915,\n",
       " 'feature102': 0.04969530517885755,\n",
       " 'feature103': 0.12285064709232289,\n",
       " 'feature104': 0.0073138861048714894,\n",
       " 'feature105': 0.0721395479612338,\n",
       " 'feature106': 0.039970036577837924,\n",
       " 'feature107': 0.10960259792404546,\n",
       " 'feature108': 0.04305428806783829,\n",
       " 'feature109': 0.025097951682383803,\n",
       " 'feature110': 0.028250701068589644,\n",
       " 'feature111': 0.007870877388832553,\n",
       " 'feature112': 0.019377956335746238,\n",
       " 'feature113': 0.024821742597007347,\n",
       " 'feature114': 0.020639334562293266,\n",
       " 'feature115': 0.019187828752575884,\n",
       " 'feature116': 0.03525718386562505,\n",
       " 'feature117': 0.0580463914073956,\n",
       " 'feature118': 0.4285824776533526,\n",
       " 'feature120': 0.02667520362707056,\n",
       " 'feature121': 0.1292130685377972,\n",
       " 'feature122': 0.35858557055090057,\n",
       " 'feature123': 0.009318506970022946,\n",
       " 'feature124': 0.061060938787545885,\n",
       " 'feature125': 0.028741963047054453,\n",
       " 'feature127': 0.06930108176019997,\n",
       " 'feature128': 0.012522119382776972,\n",
       " 'feature133': 0.02766811210381351,\n",
       " 'feature136': 0.06337794676592162,\n",
       " 'feature137': 0.08771235332544791,\n",
       " 'feature138': 0.010306367026342841,\n",
       " 'feature139': 0.10893959813844509,\n",
       " 'feature140': 0.018136481844387736,\n",
       " 'feature141': 0.0661150056266911,\n",
       " 'feature143': 0.08597561477067119,\n",
       " 'feature144': 0.0,\n",
       " 'feature145': 0.11811301518502608,\n",
       " 'feature146': 0.0029407921687000585,\n",
       " 'feature147': 0.11682504099975514,\n",
       " 'feature148': 0.018283158600851685,\n",
       " 'feature149': 0.06582156813292017,\n",
       " 'feature150': 0.04673320857181913,\n",
       " 'feature151': 0.04184184995694053,\n",
       " 'feature152': 0.06500933936569368,\n",
       " 'feature153': 0.11063725235632667,\n",
       " 'feature154': 0.08856582762542173,\n",
       " 'feature155': 0.07234099581525713,\n",
       " 'feature156': 0.07104520365258292,\n",
       " 'feature157': 0.07878781854983316,\n",
       " 'feature158': 0.034511805551065075,\n",
       " 'feature160': 0.0,\n",
       " 'feature161': 0.03330483455402552,\n",
       " 'feature162': 0.05897332732094448,\n",
       " 'feature163': 0.04961275396440131,\n",
       " 'feature164': 0.060424314062499485,\n",
       " 'feature165': 0.033324557154204,\n",
       " 'feature166': 0.010994827112895537,\n",
       " 'feature167': 0.002837765676640403,\n",
       " 'feature168': 0.020965091614088067,\n",
       " 'feature169': 0.004654327278276824,\n",
       " 'feature170': 0.0029717852150029766,\n",
       " 'feature171': 0.055637732429885525,\n",
       " 'feature172': 0.09048409729737729,\n",
       " 'feature173': 0.056648675696476025,\n",
       " 'feature174': 0.09179490066268106,\n",
       " 'feature175': 0.05428795583278809,\n",
       " 'feature176': 0.05188601728411198,\n",
       " 'feature177': 0.03845452097425486,\n",
       " 'feature178': 0.07228920304454374,\n",
       " 'feature179': 0.1281082593191147,\n",
       " 'feature180': 0.08584682596007981,\n",
       " 'feature181': 0.1357537751600628,\n",
       " 'feature182': 0.2539777461698432,\n",
       " 'feature183': 0.15094974155213126,\n",
       " 'feature184': 0.0700704860235883,\n",
       " 'feature185': 0.14705210943589989,\n",
       " 'feature186': 0.01969686696416216,\n",
       " 'feature187': 0.2161428696643368,\n",
       " 'feature188': 0.2825034885762961,\n",
       " 'feature189': 0.5247101985175968,\n",
       " 'feature191': 1.0590013820245372,\n",
       " 'feature192': 0.5310685793136635,\n",
       " 'feature193': 0.4357407184756362,\n",
       " 'feature194': 0.1280757626169958,\n",
       " 'feature195': 0.43818847106313485,\n",
       " 'feature196': 0.007232191755269496,\n",
       " 'feature197': 0.024760387988755347,\n",
       " 'feature199': 0.05842478182869811,\n",
       " 'feature200': 0.06906435614142212,\n",
       " 'feature202': 0.05567857072053713,\n",
       " 'feature203': 0.0053890279413095835,\n",
       " 'feature204': 0.039435617898452256,\n",
       " 'feature205': 0.00030449949454985936,\n",
       " 'feature208': 1.5928160499827517,\n",
       " 'feature210': 1.999212638435675,\n",
       " 'feature214': 0.005009336831549096,\n",
       " 'feature215': 0.0018469488670990204,\n",
       " 'feature216': 0.0021563511736288213,\n",
       " 'feature217': 0.006187858523274,\n",
       " 'feature218': 0.06870615704987097,\n",
       " 'feature220': 0.06801344588240334,\n",
       " 'feature224': 0.001161922498985692,\n",
       " 'feature225': 0.0009276729931751976,\n",
       " 'feature226': 0.18461384148831964,\n",
       " 'feature227': 0.00475002439324445,\n",
       " 'feature229': 0.0,\n",
       " 'feature230': 0.005075234200035317,\n",
       " 'feature231': 0.004405957860558984,\n",
       " 'feature232': 0.0,\n",
       " 'feature233': 0.12103280143920062,\n",
       " 'feature234': 0.07226855418160964,\n",
       " 'feature243': 0.021150454961696683,\n",
       " 'feature244': 0.04280713241196929,\n",
       " 'feature260': 0.027370490770186683,\n",
       " 'feature264': 0.033743580337339096,\n",
       " 'feature268': 0.056076353668998054,\n",
       " 'feature273': 0.0026170665718572112,\n",
       " 'feature274': 0.007899229700703869,\n",
       " 'feature275': 0.007486437080901412,\n",
       " 'feature276': 0.0038710251636463536,\n",
       " 'feature277': 0.01413638057663701,\n",
       " 'feature278': 0.006282276591302332,\n",
       " 'feature279': 0.014745612658244981,\n",
       " 'feature280': 0.031480778521851174,\n",
       " 'feature281': 2.529279637914763e-05,\n",
       " 'feature282': 0.13065770350229472,\n",
       " 'feature285': 0.000118175698303954,\n",
       " 'feature286': 0.0452797386255405,\n",
       " 'feature287': 0.22994829745040285,\n",
       " 'feature288': 0.11378624427746296,\n",
       " 'feature289': 0.009099516695704277,\n",
       " 'feature290': 0.05387101203244294,\n",
       " 'feature291': 0.024866477620415606,\n",
       " 'feature292': 0.0,\n",
       " 'feature293': 6.897464857016435e-06,\n",
       " 'feature294': 0.011642410538412334,\n",
       " 'feature295': 4.923396815402042e-05,\n",
       " 'feature296': 0.0026860123750187355,\n",
       " 'feature297': 0.0017289156212168854,\n",
       " 'feature298': 0.0,\n",
       " 'feature299': 0.005873396167403564,\n",
       " 'feature300': 0.01775662598722152,\n",
       " 'feature301': 0.0,\n",
       " 'feature302': 1.816103929336687e-05,\n",
       " 'feature303': 0.01382028420611876,\n",
       " 'feature304': 0.0544050756615628,\n",
       " 'feature305': 0.05294783114474352,\n",
       " 'feature306': 0.0,\n",
       " 'feature307': 0.0064768357772175015,\n",
       " 'feature308': 0.02274799890385283,\n",
       " 'feature309': 0.5048012127998097,\n",
       " 'feature310': 0.5005381221642332,\n",
       " 'feature311': 0.015245472113369126,\n",
       " 'feature316': 0.019951876834632842,\n",
       " 'feature318': 4.81493799588659,\n",
       " 'feature320': 1.6019621538795457,\n",
       " 'feature321': 0.0,\n",
       " 'feature322': 0.08838614907725904,\n",
       " 'feature324': 0.01576729295254106,\n",
       " 'feature325': 1.0295697226207974e-05,\n",
       " 'feature328': 0.0,\n",
       " 'feature329': 0.002303217173076895,\n",
       " 'feature330': 0.00622390225013341,\n",
       " 'feature331': 0.008813207544568356,\n",
       " 'feature332': 0.007457598224738116,\n",
       " 'feature333': 0.005985845173745906,\n",
       " 'feature334': 0.005532581298528869,\n",
       " 'feature335': 0.04526560693042994,\n",
       " 'feature336': 0.02470048301860253,\n",
       " 'feature337': 0.017882192106374938,\n",
       " 'feature338': 0.006835744175413545,\n",
       " 'feature339': 0.0,\n",
       " 'feature340': 0.13684414582543505,\n",
       " 'feature341': 5.235199196130802,\n",
       " 'feature342': 0.31866521675275866,\n",
       " 'feature343': 0.01956451863301766,\n",
       " 'feature344': 0.048689356040785135,\n",
       " 'feature345': 0.016590861285103127,\n",
       " 'feature346': 0.16620201433717707,\n",
       " 'feature349': 1.1195995637358156,\n",
       " 'feature350': 0.5485139670044916,\n",
       " 'feature352': 0.03302736375435085,\n",
       " 'feature353': 0.013385784250342328,\n",
       " 'feature354': 0.012447098942315021,\n",
       " 'feature355': 0.043826824325437636,\n",
       " 'feature356': 1.0610851205023648,\n",
       " 'feature357': 1.4508682237513337,\n",
       " 'feature358': 0.21587961610290202,\n",
       " 'feature359': 0.03768766878091974,\n",
       " 'feature366': 0.0384096656775327,\n",
       " 'feature367': 0.13287418779518326,\n",
       " 'feature369': 0.02517597158541256,\n",
       " 'feature370': 0.11153813106629605,\n",
       " 'feature384': 0.0024165072131904905,\n",
       " 'feature385': 0.03612049093071302,\n",
       " 'feature386': 0.007726463513555948,\n",
       " 'feature387': 0.0,\n",
       " 'feature388': 0.000909593622863926,\n",
       " 'feature389': 0.0,\n",
       " 'feature390': 0.0014629550725711404,\n",
       " 'feature391': 0.012594722048097917,\n",
       " 'feature392': 0.005922384511747583,\n",
       " 'feature393': 0.03530501185840534,\n",
       " 'feature394': 0.0,\n",
       " 'feature395': 0.004580473081456175,\n",
       " 'feature399': 0.01863844161687515,\n",
       " 'feature400': 0.0,\n",
       " 'feature401': 0.0,\n",
       " 'feature404': 0.0,\n",
       " 'feature405': 0.4103076786060416,\n",
       " 'feature406': 0.0,\n",
       " 'feature407': 0.0,\n",
       " 'feature408': 0.0,\n",
       " 'feature409': 0.020111404497484057,\n",
       " 'feature410': 0.010483601070108123,\n",
       " 'feature411': 0.01168703806895031,\n",
       " 'feature412': 0.004292298936935277,\n",
       " 'feature413': 0.0068390901965567075,\n",
       " 'feature415': 0.0025500447919209034,\n",
       " 'feature416': 0.019139576103898968,\n",
       " 'feature417': 0.007425573675454979,\n",
       " 'feature418': 0.0,\n",
       " 'feature420': 0.0013552316747734339,\n",
       " 'feature422': 0.012912347192607134,\n",
       " 'feature423': 0.0,\n",
       " 'feature425': 0.004432682994104472,\n",
       " 'feature426': 0.021194010651848342,\n",
       " 'feature427': 0.016823940330102063,\n",
       " 'feature428': 0.0222419933914712,\n",
       " 'feature429': 0.04533363983459789,\n",
       " 'feature431': 0.002191129031618108,\n",
       " 'feature433': 0.025023597633020696,\n",
       " 'feature434': 0.00917262377019125,\n",
       " 'feature435': 0.18387494312512687,\n",
       " 'feature437': 0.0359300872387819,\n",
       " 'feature439': 0.013013414871030759,\n",
       " 'feature440': 0.047637948748224586,\n",
       " 'feature441': 0.0543872648415485,\n",
       " 'feature442': 0.05133676207127159,\n",
       " 'feature444': 0.9640037169308909,\n",
       " 'feature446': 0.11524352611254189,\n",
       " 'feature447': 0.013341735986818523,\n",
       " 'feature448': 0.04298542484491981,\n",
       " 'feature450': 0.14443085611053466,\n",
       " 'feature451': 0.04659071759805779,\n",
       " 'feature452': 0.05441332497974335,\n",
       " 'feature453': 0.05498691761330786,\n",
       " 'feature454': 0.13211834471646605,\n",
       " 'feature455': 0.043804139686087006,\n",
       " 'feature456': 0.029999560247059274,\n",
       " 'feature459': 0.06942320080595608,\n",
       " 'feature461': 0.049366615891102826,\n",
       " 'feature462': 0.02030872926160675,\n",
       " 'feature463': 0.0,\n",
       " 'feature464': 0.0,\n",
       " 'feature465': 0.0,\n",
       " 'feature468': 0.02852926432764691,\n",
       " 'feature469': 0.07337852967997065,\n",
       " 'feature470': 0.16594264266098901,\n",
       " 'feature471': 0.011971785484131428,\n",
       " 'feature472': 0.42503369906257965,\n",
       " 'feature473': 0.007462376114861894,\n",
       " 'feature475': 0.0535408378930903,\n",
       " 'feature476': 0.0,\n",
       " 'feature477': 0.09900920304871363,\n",
       " 'feature478': 0.002184401784043618,\n",
       " 'feature485': 0.015270990746509432,\n",
       " 'feature488': 0.04994599251449913,\n",
       " 'feature489': 0.053243198396600765,\n",
       " 'feature490': 0.06998193975449905,\n",
       " 'feature491': 0.14878205861908458,\n",
       " 'feature492': 0.007142981957478444,\n",
       " 'feature493': 0.06536789312672403,\n",
       " 'feature495': 0.04238672728812257,\n",
       " 'feature496': 0.0,\n",
       " 'feature497': 0.0904471647149955,\n",
       " 'feature498': 0.0027228077298512175,\n",
       " 'feature500': 0.0332476434419418,\n",
       " 'feature501': 0.11490326224893761,\n",
       " 'feature502': 0.003791693718767769,\n",
       " 'feature503': 0.10027333089667483,\n",
       " 'feature504': 0.09563742653849008,\n",
       " 'feature505': 0.08165676601617847,\n",
       " 'feature506': 0.04621801704046906,\n",
       " 'feature507': 0.03719899584188417,\n",
       " 'feature508': 0.36335052030621023,\n",
       " 'feature509': 0.030209536644915214,\n",
       " 'feature510': 0.02514735124925211,\n",
       " 'feature511': 0.0,\n",
       " 'feature513': 0.05730997749117077,\n",
       " 'feature515': 0.06064421562315068,\n",
       " 'feature516': 0.058210070180460434,\n",
       " 'feature517': 0.01374511278339045,\n",
       " 'feature518': 0.05700378401463106,\n",
       " 'feature521': 0.004783659114617694,\n",
       " 'feature522': 0.0282691218717173,\n",
       " 'feature524': 0.031380150782069106,\n",
       " 'feature525': 0.0566319031537245,\n",
       " 'feature526': 0.03647995459937851,\n",
       " 'feature527': 0.07193676386750075,\n",
       " 'feature528': 0.034521768248005485,\n",
       " 'feature529': 0.10595243461021751,\n",
       " 'feature530': 0.10761703884208167,\n",
       " 'feature531': 0.06836139782856532,\n",
       " 'feature532': 0.2626986410331278,\n",
       " 'feature533': 0.09488869369456289,\n",
       " 'feature534': 0.8090307439349678,\n",
       " 'feature535': 0.06523282452905171,\n",
       " 'feature536': 0.0,\n",
       " 'feature537': 0.0,\n",
       " 'feature538': 0.047709350397312944,\n",
       " 'feature539': 0.011009277905198189,\n",
       " 'feature540': 0.07618864319663361,\n",
       " 'feature541': 0.01093120887512168,\n",
       " 'feature542': 0.017734884002189987,\n",
       " 'feature543': 0.46440408804807104,\n",
       " 'feature544': 0.0,\n",
       " 'feature545': 0.0,\n",
       " 'feature546': 0.3689107395564904,\n",
       " 'feature547': 0.06096309765564465,\n",
       " 'feature548': 0.5688639889940186,\n",
       " 'feature550': 0.020191132048467057,\n",
       " 'feature551': 1.0093559223254083,\n",
       " 'feature552': 0.08493727022449586,\n",
       " 'feature553': 0.09927102083256854,\n",
       " 'feature554': 0.10199158459576287,\n",
       " 'feature555': 0.0,\n",
       " 'feature556': 0.0,\n",
       " 'feature557': 0.045654893247676145,\n",
       " 'feature558': 0.007334961591382307,\n",
       " 'feature559': 0.09487804571882462,\n",
       " 'feature561': 0.5055970783902654,\n",
       " 'feature562': 0.012328107705683522,\n",
       " 'feature563': 0.006377315878868013,\n",
       " 'feature564': 0.03434842113402434,\n",
       " 'feature565': 0.00445485133749178,\n",
       " 'feature566': 0.0,\n",
       " 'feature567': 0.0,\n",
       " 'feature568': 0.0,\n",
       " 'feature570': 0.0,\n",
       " 'feature571': 0.00241304364109522,\n",
       " 'feature572': 0.38149966652711614,\n",
       " 'feature574': 0.0,\n",
       " 'feature575': 0.0,\n",
       " 'feature578': 0.0,\n",
       " 'feature587': 0.0503204557190128,\n",
       " 'feature588': 0.009453028937380854,\n",
       " 'feature597': 0.03709061741737046,\n",
       " 'feature599': 0.010974839818989682,\n",
       " 'feature616': 0.0,\n",
       " 'feature617': 0.0,\n",
       " 'feature619': 0.0,\n",
       " 'feature620': 0.03414218352610428,\n",
       " 'feature622': 0.0,\n",
       " 'feature624': 0.0,\n",
       " 'feature625': 0.0,\n",
       " 'feature627': 0.0,\n",
       " 'feature628': 0.0009843370419340572,\n",
       " 'feature630': 0.0,\n",
       " 'feature631': 0.0,\n",
       " 'feature633': 0.0,\n",
       " 'feature634': 0.013599989531900758,\n",
       " 'feature637': 0.0,\n",
       " 'feature639': 0.0,\n",
       " 'feature640': 0.0,\n",
       " 'feature642': 0.0,\n",
       " 'feature644': 0.0,\n",
       " 'feature648': 0.02551872492169728,\n",
       " 'feature649': 0.005825416020894647,\n",
       " 'feature650': 0.0,\n",
       " 'feature651': 0.04758745380630913,\n",
       " 'feature652': 0.0,\n",
       " 'feature653': 0.009456170708920707,\n",
       " 'feature654': 0.0,\n",
       " 'feature656': 0.0012935646924705805,\n",
       " 'feature657': 0.014937850071781706,\n",
       " 'feature658': 0.0,\n",
       " 'feature659': 0.0063938262156132296,\n",
       " 'feature660': 0.00359119896952629,\n",
       " 'feature661': 0.0,\n",
       " 'feature662': 0.0,\n",
       " 'feature663': 0.0,\n",
       " 'feature664': 0.004391185289245002,\n",
       " 'feature665': 0.0031171196911933536,\n",
       " 'feature666': 0.028770786205412492,\n",
       " 'feature667': 0.007851582541928175,\n",
       " 'feature668': 0.025854562358494107,\n",
       " 'feature669': 0.0,\n",
       " 'feature670': 0.0,\n",
       " 'feature671': 0.0,\n",
       " 'feature672': 0.0,\n",
       " 'feature674': 0.008136696513135136,\n",
       " 'feature675': 0.03953324795541232,\n",
       " 'feature677': 0.010647371091677146,\n",
       " 'feature678': 0.0,\n",
       " 'feature680': 0.0,\n",
       " 'feature682': 0.0,\n",
       " 'feature683': 0.0,\n",
       " 'feature684': 0.0075278052293812165,\n",
       " 'feature685': 0.0,\n",
       " 'feature686': 0.0,\n",
       " 'feature687': 0.0051436778436941034,\n",
       " 'feature688': 0.05888050713051559,\n",
       " 'feature689': 0.007223572514632493,\n",
       " 'feature690': 0.01022886707545739,\n",
       " 'feature692': 0.005095780304467491,\n",
       " 'feature693': 0.00694585761948244,\n",
       " 'feature694': 0.0,\n",
       " 'feature695': 0.0,\n",
       " 'feature697': 0.0,\n",
       " 'feature698': 0.0034392802951569872,\n",
       " 'feature699': 0.0,\n",
       " 'feature700': 0.0,\n",
       " 'feature701': 0.0,\n",
       " 'feature702': 0.0,\n",
       " 'feature703': 0.0077168350584978,\n",
       " 'feature704': 0.0,\n",
       " 'feature705': 0.0,\n",
       " 'feature706': 0.0,\n",
       " 'feature707': 0.0,\n",
       " 'feature708': 0.0,\n",
       " 'feature709': 0.0,\n",
       " 'feature710': 0.0,\n",
       " 'feature711': 1.820203915531634e-05,\n",
       " 'feature712': 0.016861897815198333,\n",
       " 'feature713': 1.6051920744695671,\n",
       " 'feature715': 0.826233642936469,\n",
       " 'feature716': 0.014582628709313789,\n",
       " 'feature717': 0.059409058827456424,\n",
       " 'feature719': 0.0,\n",
       " 'feature720': 0.007432193000949713,\n",
       " 'feature721': 0.022490469496496728,\n",
       " 'feature723': 0.0,\n",
       " 'feature726': 0.0,\n",
       " 'feature729': 0.0,\n",
       " 'feature732': 0.006966652264952419,\n",
       " 'feature735': 0.0,\n",
       " 'feature738': 0.0,\n",
       " 'feature741': 0.0,\n",
       " 'feature748': 0.00022435614365950646,\n",
       " 'feature749': 0.007727419902896285,\n",
       " 'feature750': 0.17554863791292125,\n",
       " 'feature751': 0.04745058804895813,\n",
       " 'feature752': 0.0011526526419875826,\n",
       " 'feature753': 0.028301721179047754,\n",
       " 'feature754': 0.05503281871322898,\n",
       " 'feature755': 0.1652009545835298,\n",
       " 'feature756': 0.0,\n",
       " 'feature757': 0.013080302006009521,\n",
       " 'feature758': 0.25738666037373403,\n",
       " 'feature759': 0.018077695816918527,\n",
       " 'feature761': 0.0,\n",
       " 'feature762': 0.01345172619201786,\n",
       " 'feature763': 0.058547867118318345,\n",
       " 'feature764': 0.015989659891738693,\n",
       " 'feature765': 0.0,\n",
       " 'feature768': 0.0005370758397990042,\n",
       " 'feature769': 0.004418589252101109,\n",
       " 'feature770': 0.0,\n",
       " 'feature772': 0.08817179723961908,\n",
       " 'feature773': 0.01968934764334167,\n",
       " 'feature774': 0.0,\n",
       " 'feature775': 0.00025123881093869286,\n",
       " 'feature776': 0.00918205871067372,\n",
       " 'feature777': 0.030665237609218955,\n",
       " 'feature778': 0.010131980068789416,\n",
       " 'feature779': 0.01449294828645674,\n",
       " 'feature780': 0.003186652166981273,\n",
       " 'feature781': 0.043040919554609355,\n",
       " 'feature782': 0.6035017058146915,\n",
       " 'feature783': 0.642791816367681,\n",
       " 'feature785': 0.0,\n",
       " 'feature786': 0.0,\n",
       " 'feature787': 0.0,\n",
       " 'feature788': 0.004948904662996582,\n",
       " 'feature790': 0.0,\n",
       " 'feature791': 0.004313608449068994,\n",
       " 'feature792': 0.01530459882956367,\n",
       " 'feature793': 0.022567475781546276,\n",
       " 'feature794': 0.0,\n",
       " 'feature795': 0.023678952564334044,\n",
       " 'feature796': 0.0,\n",
       " 'feature797': 0.02148861806371767,\n",
       " 'feature799': 0.12138997815787524,\n",
       " 'feature800': 0.035714030179633795,\n",
       " 'feature801': 0.0,\n",
       " 'feature802': 0.0,\n",
       " 'feature804': 0.010695218942999631,\n",
       " 'feature805': 0.03881073996704718,\n",
       " 'feature806': 0.0,\n",
       " 'feature807': 0.0,\n",
       " 'feature808': 0.0,\n",
       " 'feature809': 0.0,\n",
       " 'feature810': 0.08753212178577109,\n",
       " 'feature811': 0.014552939988953536,\n",
       " 'feature813': 0.014216670755258069,\n",
       " 'feature815': 0.028528102166629574,\n",
       " 'feature816': 0.0,\n",
       " 'feature817': 0.3055271497013946,\n",
       " 'feature818': 0.0,\n",
       " 'feature819': 0.0,\n",
       " 'feature820': 0.031766834112163786,\n",
       " 'feature821': 0.0014532332793794319,\n",
       " 'feature823': 0.0005108640485495845,\n",
       " 'feature825': 0.007117594119724492,\n",
       " 'feature829': 0.0041197406527453085,\n",
       " 'feature830': 0.0033002876722455373,\n",
       " 'feature831': 0.01537956890534616,\n",
       " 'feature832': 0.005182511471993183,\n",
       " 'feature833': 0.0031226444700365253,\n",
       " 'feature837': 0.008449734189035574,\n",
       " 'feature841': 0.002423934775117302,\n",
       " 'feature842': 0.0,\n",
       " 'feature843': 0.004885873348235047,\n",
       " 'feature844': 0.0024702226253704245,\n",
       " 'feature845': 0.0065920712731331816,\n",
       " 'feature849': 0.011196339829925154,\n",
       " 'feature851': 0.03502698823402836,\n",
       " 'feature854': 0.06461691752212023,\n",
       " 'feature855': 0.004614981285680712,\n",
       " 'feature856': 0.06341720485851887,\n",
       " 'feature861': 0.2295702884424664,\n",
       " 'feature862': 0.1058553672542876,\n",
       " 'feature869': 0.03491166957173721,\n",
       " 'feature870': 0.018668767654964186,\n",
       " 'feature871': 0.23245237052166326,\n",
       " 'feature872': 0.09505010946004369,\n",
       " 'feature873': 0.09903373282066111,\n",
       " 'feature876': 0.09299670471604343,\n",
       " 'feature878': 0.05075066500709633,\n",
       " 'feature879': 0.055648574654749046,\n",
       " 'feature880': 0.008858273782583843,\n",
       " 'feature884': 0.0027563029604704293,\n",
       " 'feature885': 0.002870550406563427,\n",
       " 'feature886': 0.0,\n",
       " 'feature888': 0.0,\n",
       " 'feature889': 0.0,\n",
       " 'feature890': 0.11133522225336899,\n",
       " 'feature891': 0.02731186509902183,\n",
       " 'feature892': 0.029325279561134177,\n",
       " 'feature893': 0.09947112713904561,\n",
       " 'feature894': 0.08641633237821293,\n",
       " 'feature897': 0.00915929257391581,\n",
       " 'feature898': 0.24632192213845908,\n",
       " 'feature916': 0.37457683856221385,\n",
       " 'feature917': 0.12408084640468689,\n",
       " 'feature918': 0.13049072309440932,\n",
       " 'feature919': 0.18007925143140943,\n",
       " 'feature920': 2.094835655166125,\n",
       " 'feature921': 0.005236342794230416,\n",
       " 'feature922': 1.430614367486066,\n",
       " 'feature923': 0.02037162881602079,\n",
       " 'feature924': 0.02297710356187827,\n",
       " 'feature925': 0.011502721179196786,\n",
       " 'feature926': 0.02440665881799952,\n",
       " 'feature927': 0.040654868175984425,\n",
       " 'feature928': 0.4186123796087406,\n",
       " 'feature929': 0.08020560969736171,\n",
       " 'feature930': 0.4267822503575441,\n",
       " 'feature932': 0.019458535150392576,\n",
       " 'feature934': 0.2550761546850874,\n",
       " 'feature935': 1.1006155490999237,\n",
       " 'feature936': 1.4525854225413002,\n",
       " 'feature937': 0.19536966170381243,\n",
       " 'feature938': 0.7385516637872661,\n",
       " 'feature939': 0.42385762873847443,\n",
       " 'feature940': 1.6432879895079537,\n",
       " 'feature941': 0.928800031100581,\n",
       " 'feature942': 1.7099726734301959,\n",
       " 'feature945': 0.38347691020743335,\n",
       " 'feature946': 0.6840990384804816,\n",
       " 'feature947': 0.21736637693283664,\n",
       " 'feature950': 1.7720891338344473,\n",
       " 'feature951': 2.399163474479297,\n",
       " 'feature955': 0.0,\n",
       " 'feature956': 0.0,\n",
       " 'feature957': 0.0,\n",
       " 'feature958': 0.0,\n",
       " 'feature959': 0.0,\n",
       " 'feature960': 0.0,\n",
       " 'feature961': 0.0,\n",
       " 'feature962': 0.0,\n",
       " 'feature963': 0.0,\n",
       " 'feature964': 0.0,\n",
       " 'feature965': 0.0,\n",
       " 'feature966': 0.0,\n",
       " 'feature967': 0.0,\n",
       " 'feature968': 0.0,\n",
       " 'feature969': 0.0,\n",
       " 'feature970': 0.0,\n",
       " 'feature971': 0.0,\n",
       " 'feature972': 0.0,\n",
       " 'feature973': 0.0,\n",
       " 'feature974': 0.0,\n",
       " 'feature975': 0.0,\n",
       " 'feature976': 0.0,\n",
       " 'feature977': 0.0,\n",
       " 'feature978': 0.0,\n",
       " 'feature979': 0.0,\n",
       " 'feature980': 0.0,\n",
       " 'feature981': 0.0,\n",
       " 'feature982': 0.0,\n",
       " 'feature983': 0.0,\n",
       " 'feature984': 0.0,\n",
       " 'feature985': 0.6841242299903179,\n",
       " 'feature986': 0.040284134008811014,\n",
       " 'feature987': 0.056381972888652925,\n",
       " 'feature988': 1.4848570474965064,\n",
       " 'feature989': 0.4993864607186929,\n",
       " 'feature990': 1.6865618255792763,\n",
       " 'feature991': 0.5719217805874391,\n",
       " 'feature994': 5.670129746754657,\n",
       " 'feature995': 0.13186096743170114,\n",
       " 'feature996': 0.19613333503843774,\n",
       " 'feature997': 0.26333788353711035,\n",
       " 'feature998': 1.2641925044244282,\n",
       " 'feature999': 0.16996194048527444,\n",
       " 'feature1000': 1.59383957197794,\n",
       " 'feature1001': 0.4219318610422782,\n",
       " 'feature1004': 7.256061271196149,\n",
       " 'feature1005': 0.0,\n",
       " 'feature1006': 0.0,\n",
       " 'feature1007': 0.0,\n",
       " 'feature1008': 0.0,\n",
       " 'feature1009': 0.0,\n",
       " 'feature1010': 0.0,\n",
       " 'feature1011': 0.0,\n",
       " 'feature1012': 0.0,\n",
       " 'feature1013': 0.0,\n",
       " 'feature1014': 0.0,\n",
       " 'feature1015': 0.0,\n",
       " 'feature1016': 0.0,\n",
       " 'feature1017': 0.0,\n",
       " 'feature1018': 0.0,\n",
       " 'feature1019': 0.0,\n",
       " 'feature1020': 0.0,\n",
       " 'feature1021': 0.0,\n",
       " 'feature1022': 0.0,\n",
       " 'feature1023': 0.0,\n",
       " 'feature1024': 0.0,\n",
       " 'feature1025': 0.0,\n",
       " 'feature1026': 0.0,\n",
       " 'feature1027': 0.0,\n",
       " 'feature1028': 0.0,\n",
       " 'feature1029': 0.0,\n",
       " 'feature1030': 0.0,\n",
       " 'feature1031': 0.0,\n",
       " 'feature1032': 0.0,\n",
       " 'feature1033': 0.0,\n",
       " 'feature1034': 0.0,\n",
       " 'feature1035': 0.12350653954008249,\n",
       " 'feature1036': 0.5864074675955457,\n",
       " 'feature1037': 0.0023454890080738754,\n",
       " 'feature1042': 0.0530790200463827,\n",
       " 'feature1043': 0.0253512894031477,\n",
       " 'feature1049': 0.003211007313965339,\n",
       " 'feature1050': 0.002803014973677994,\n",
       " 'feature1051': 0.00294205956849333,\n",
       " 'feature1052': 0.006436787982953067,\n",
       " 'feature1053': 0.0,\n",
       " 'feature1054': 0.009087031218697807,\n",
       " 'feature1055': 0.019554117906474017,\n",
       " 'feature1056': 0.10685717990564743,\n",
       " 'feature1057': 0.05212798447988516,\n",
       " 'feature1059': 0.07764212232161138,\n",
       " 'feature1063': 0.042842595175278414,\n",
       " 'feature1064': 0.07663361308363667,\n",
       " 'feature1065': 0.07782128815555642,\n",
       " 'feature1066': 0.07148423784662893,\n",
       " 'feature1068': 0.11940567476655334,\n",
       " 'feature1069': 0.2570888320764528}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt    \n",
    "from fastparquet import ParquetFile\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "from utils import remove_highly_correlated_features, feature_drop\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "file_path = \"Data/train_ai_comp_final_dp.parquet\"\n",
    "pf = ParquetFile(file_path)\n",
    "df = pf.to_pandas()\n",
    "\n",
    "fature_to_drop = remove_highly_correlated_features(df, threshold=0.94)\n",
    "df.drop(columns=fature_to_drop, inplace=True)\n",
    "df = feature_drop(df)\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Artem cat features \n",
    "cat_features_tmp = ['feature5','feature6','feature7','feature9','feature74','feature85','feature96','feature106','feature117','feature127','feature138','feature150','feature163','feature174','feature215','feature293','feature343','feature344','feature345','feature346','feature347','feature348','feature349','feature350','feature352','feature356','feature360','feature363','feature364','feature374','feature379','feature381','feature383','feature389','feature393','feature395','feature396','feature397','feature398','feature399','feature400','feature401','feature402','feature403','feature404','feature408','feature409','feature410','feature411','feature412','feature413','feature415','feature416','feature417','feature419','feature421','feature422','feature425','feature427','feature428','feature430','feature431','feature432','feature436','feature437','feature438','feature439','feature441','feature442','feature443','feature444','feature445','feature446','feature447','feature448','feature449','feature450','feature452','feature453','feature454','feature459','feature460','feature463','feature465','feature466','feature472','feature474','feature475','feature476','feature477','feature478','feature479','feature480','feature481','feature483','feature485','feature486','feature488','feature490','feature491','feature492','feature493','feature494','feature497','feature498','feature499','feature500','feature501','feature502','feature504','feature505','feature508','feature509','feature510','feature512','feature513','feature514','feature515','feature516','feature517','feature519','feature520','feature521','feature524','feature525','feature526','feature527','feature528','feature534','feature535','feature538','feature539','feature541','feature542','feature543','feature544','feature547','feature548','feature549','feature550','feature552','feature553','feature554','feature557','feature558','feature559','feature560','feature577','feature580','feature581','feature594','feature596','feature597','feature598','feature599','feature600','feature601','feature602','feature604','feature606','feature608','feature609','feature610','feature611','feature612','feature613','feature616','feature617','feature619','feature620','feature621','feature622','feature631','feature634','feature639','feature644','feature647','feature650','feature654','feature660','feature664','feature666','feature668','feature672','feature673','feature682','feature692','feature695','feature698','feature705','feature712','feature740','feature741','feature743','feature744','feature746','feature747','feature750','feature751','feature753','feature754','feature757','feature758','feature760','feature763','feature766','feature767','feature769','feature770','feature771','feature773','feature776','feature777','feature786','feature787','feature788','feature789','feature790','feature791','feature792','feature794','feature795','feature796','feature797','feature800','feature803','feature804','feature805','feature811','feature812','feature813','feature814','feature815','feature835','feature838','feature842','feature843','feature845','feature851','feature853','feature855','feature857','feature861','feature863','feature864','feature866','feature868','feature870','feature873','feature875','feature877','feature879','feature881','feature884','feature887','feature927','feature928','feature929','feature930','feature931','feature932','feature937','feature991','feature992','feature993','feature994','feature995','feature996','feature997','feature998','feature999','feature1000','feature1003','feature1062','feature1063','feature1064','feature1065','feature1066','feature1068','feature1069','feature1070','feature1071','feature1072','feature1073','feature1074','feature1075','feature1076']\n",
    "cat_features = [feature for feature in cat_features_tmp if feature in df.columns]\n",
    "\n",
    "# convert cats to string\n",
    "for col in cat_features:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "\n",
    "X = df.drop([\"target\"], axis = 1)\n",
    "y = df['target']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "model = CatBoostClassifier(iterations=1000, learning_rate=0.01, depth=8, loss_function='Logloss', cat_features=cat_features)\n",
    "model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50, verbose=100)\n",
    "\n",
    "\n",
    "# metrics\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "y_pred = model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {classification_report(y_test, y_pred)}')\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba.ravel()[1::2])\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "\n",
    "\n",
    "# sorted feature importance\n",
    "feature_weights = {feature: weight for feature, weight in zip(X.columns, model.feature_importances_)}\n",
    "dict(sorted(feature_weights.items(), key=lambda item: item[1], reverse=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "students2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
